{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from Survival.Utils import load_val_data\n",
    "from Survival.Utils import load_score_containers\n",
    "from Survival.Utils import calc_scores\n",
    "from Survival.Utils import filename_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current dataset: pancreatitis\n",
      "---------------------------------------------\n",
      "fold 0\n",
      "1106 13:14:21\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/fancyimpute/soft_impute.py:100: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return (np.sqrt(ssd) / old_norm) < self.convergence_threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 35\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 1\n",
      "1106 13:14:37\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 36\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 2\n",
      "1106 13:14:52\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 39\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 3\n",
      "1106 13:15:06\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 37\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 4\n",
      "1106 13:15:22\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 40\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 5\n",
      "1106 13:15:38\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 38\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 6\n",
      "1106 13:15:55\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 40\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 7\n",
      "1106 13:16:10\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 37\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 8\n",
      "1106 13:16:25\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 37\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 9\n",
      "1106 13:16:41\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 36\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 10\n",
      "1106 13:16:56\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 34\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 11\n",
      "1106 13:17:11\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 39\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 12\n",
      "1106 13:17:27\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 35\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 13\n",
      "1106 13:17:43\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 34\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 14\n",
      "1106 13:17:57\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 30\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 15\n",
      "1106 13:18:13\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 32\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 16\n",
      "1106 13:18:28\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 36\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 17\n",
      "1106 13:18:45\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 38\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 18\n",
      "1106 13:19:01\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 40\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 19\n",
      "1106 13:19:17\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 39\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 20\n",
      "1106 13:19:32\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 35\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 21\n",
      "1106 13:19:47\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 35\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 22\n",
      "1106 13:20:02\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 35\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 23\n",
      "1106 13:20:17\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 37\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 24\n",
      "1106 13:20:32\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 40\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 25\n",
      "1106 13:20:48\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 37\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 26\n",
      "1106 13:21:04\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 39\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 27\n",
      "1106 13:21:19\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 36\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 28\n",
      "1106 13:21:34\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 39\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 29\n",
      "1106 13:21:51\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 37\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 30\n",
      "1106 13:22:09\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 37\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 31\n",
      "1106 13:22:26\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 39\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 32\n",
      "1106 13:22:42\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 41\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 33\n",
      "1106 13:22:58\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 40\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 34\n",
      "1106 13:23:14\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 40\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 35\n",
      "1106 13:23:30\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 33\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 36\n",
      "1106 13:23:45\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 39\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 37\n",
      "1106 13:24:00\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 35\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 38\n",
      "1106 13:24:15\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 35\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 39\n",
      "1106 13:24:30\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 30\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 40\n",
      "1106 13:24:45\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 36\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 41\n",
      "1106 13:25:01\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 32\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 42\n",
      "1106 13:25:16\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 39\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 43\n",
      "1106 13:25:31\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 35\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 44\n",
      "1106 13:25:46\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 37\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 45\n",
      "1106 13:26:01\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n",
      "    Number of dumplicated featues: 35\n",
      "[LOG]Remove rows that has infinite LoS.\n",
      "---------------------------------------------\n",
      "fold 46\n",
      "1106 13:26:16\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "[LOG]Remove correlated features.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3220eac9d8f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# 0: \"pancreatitis\", 1: \"ich\", 2: \"sepsis\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_dfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_val_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"../../dataset/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Works/George Chen/Survival_Analysis/scripts/scripts/Survival/Utils.py\u001b[0m in \u001b[0;36mload_val_data\u001b[0;34m(dataset_idxs, verbose, data_path)\u001b[0m\n\u001b[1;32m    118\u001b[0m                     low_freq_value_thd=low_freq_value_thds[dataset_idx])\n\u001b[1;32m    119\u001b[0m             \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_list\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                 \u001b[0mmodel_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_id_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_id_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0mtrain_dfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mtest_dfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Works/George Chen/Survival_Analysis/scripts/scripts/Survival/Utils.py\u001b[0m in \u001b[0;36mmodel_prepare\u001b[0;34m(patient_dict, feature_set, train_id_list, test_id_list, verbose)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[LOG]Remove correlated features.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# remove correlated features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mdup_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorr_feature_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimputed_patient_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorr_thd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"    Number of dumplicated featues:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdup_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Works/George Chen/Survival_Analysis/scripts/scripts/Survival/Utils.py\u001b[0m in \u001b[0;36mcorr_feature_filter\u001b[0;34m(df, corr_thd, method)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfeature2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorr_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mcorr_thd\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                             \u001b[0mfeature1\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mfeature2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mdup_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2555\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2557\u001b[0;31m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'getitem'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2558\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2559\u001b[0m             return self._engine.get_value(s, k,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_convert_scalar_indexer\u001b[0;34m(self, key, kind)\u001b[0m\n\u001b[1;32m   1365\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'positional'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCMultiIndex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m             \u001b[0;31m# we can raise here if we are definitive that this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get the parameters\n",
    "n_neighbors = [3, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 140, 160, 180, 200]\n",
    "pca_flags = [True, False]\n",
    "dataset_idxs = [0, 1] # 0: \"pancreatitis\", 1: \"ich\", 2: \"sepsis\"\n",
    "\n",
    "train_dfs, test_dfs, dataset_names = load_val_data(dataset_idxs, verbose=True, data_path=\"../../dataset/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
