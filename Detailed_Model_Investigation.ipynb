{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Survival.Utils import load_val_data\n",
    "from Survival.Utils import load_score_containers\n",
    "from Survival.Utils import calc_scores\n",
    "from Survival.Utils import filename_generator\n",
    "\n",
    "from Survival.KNNKaplanMeier import KNNKaplanMeier\n",
    "# from Survival.CoxPHModel import CoxPHModel\n",
    "# from Survival.AalenAdditiveModel import AalenAdditiveModel\n",
    "# from Survival.WeibullRegressionModel import WeibullRegressionModel\n",
    "# from Survival.RandomSurvivalForest import RandomSurvivalForest\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current dataset: pancreatitis\n",
      "---------------------------------------------\n",
      "fold 0\n",
      "1119 00:41:02\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 1\n",
      "1119 00:41:09\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 2\n",
      "1119 00:41:17\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 3\n",
      "1119 00:41:24\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 4\n",
      "1119 00:41:32\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 5\n",
      "1119 00:41:39\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 6\n",
      "1119 00:41:46\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 7\n",
      "1119 00:41:54\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 8\n",
      "1119 00:42:02\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 9\n",
      "1119 00:42:10\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 10\n",
      "1119 00:42:18\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 11\n",
      "1119 00:42:25\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 12\n",
      "1119 00:42:32\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 13\n",
      "1119 00:42:40\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 14\n",
      "1119 00:42:47\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 15\n",
      "1119 00:42:54\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 16\n",
      "1119 00:43:01\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 17\n",
      "1119 00:43:09\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 18\n",
      "1119 00:43:16\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 19\n",
      "1119 00:43:24\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 20\n",
      "1119 00:43:31\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 21\n",
      "1119 00:43:39\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 22\n",
      "1119 00:43:46\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 23\n",
      "1119 00:43:53\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 24\n",
      "1119 00:44:01\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 25\n",
      "1119 00:44:08\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 26\n",
      "1119 00:44:15\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 27\n",
      "1119 00:44:23\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 28\n",
      "1119 00:44:30\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 29\n",
      "1119 00:44:37\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 30\n",
      "1119 00:44:45\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 31\n",
      "1119 00:44:52\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 32\n",
      "1119 00:44:59\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 33\n",
      "1119 00:45:07\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 34\n",
      "1119 00:45:14\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 35\n",
      "1119 00:45:22\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 36\n",
      "1119 00:45:29\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 37\n",
      "1119 00:45:36\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 38\n",
      "1119 00:45:44\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 39\n",
      "1119 00:45:51\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 40\n",
      "1119 00:45:59\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 41\n",
      "1119 00:46:06\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 42\n",
      "1119 00:46:13\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 43\n",
      "1119 00:46:21\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 44\n",
      "1119 00:46:28\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 45\n",
      "1119 00:46:36\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 46\n",
      "1119 00:46:43\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 47\n",
      "1119 00:46:50\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 48\n",
      "1119 00:46:58\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 49\n",
      "1119 00:47:05\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 5 times.\n",
      "[LOG]Number of events that ever occurred: 1487\n",
      "[LOG]Number of events that occurred for more than 5 times: 612\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG]Value filtering. Remove values that occurred for less than 2 times.\n",
      "[LOG]After one-hot encoding, number of feature: 997\n",
      "[LOG]Among them, number of categorical feature: 641\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "current dataset: ich\n",
      "---------------------------------------------\n",
      "fold 0\n",
      "1119 00:47:13\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 7 times.\n",
      "[LOG]Number of events that ever occurred: 1896\n",
      "[LOG]Number of events that occurred for more than 7 times: 817\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 3 times.\n",
      "[LOG]After one-hot encoding, number of feature: 1709\n",
      "[LOG]Among them, number of categorical feature: 1277\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 1\n",
      "1119 00:49:23\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 7 times.\n",
      "[LOG]Number of events that ever occurred: 1896\n",
      "[LOG]Number of events that occurred for more than 7 times: 817\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 3 times.\n",
      "[LOG]After one-hot encoding, number of feature: 1709\n",
      "[LOG]Among them, number of categorical feature: 1277\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 2\n",
      "1119 00:51:39\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 7 times.\n",
      "[LOG]Number of events that ever occurred: 1896\n",
      "[LOG]Number of events that occurred for more than 7 times: 817\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 3 times.\n",
      "[LOG]After one-hot encoding, number of feature: 1709\n",
      "[LOG]Among them, number of categorical feature: 1277\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 3\n",
      "1119 00:54:09\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 7 times.\n",
      "[LOG]Number of events that ever occurred: 1896\n",
      "[LOG]Number of events that occurred for more than 7 times: 817\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 3 times.\n",
      "[LOG]After one-hot encoding, number of feature: 1709\n",
      "[LOG]Among them, number of categorical feature: 1277\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 4\n",
      "1119 00:56:32\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 7 times.\n",
      "[LOG]Number of events that ever occurred: 1896\n",
      "[LOG]Number of events that occurred for more than 7 times: 817\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 3 times.\n",
      "[LOG]After one-hot encoding, number of feature: 1709\n",
      "[LOG]Among them, number of categorical feature: 1277\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "current dataset: sepsis\n",
      "---------------------------------------------\n",
      "fold 0\n",
      "1119 00:58:59\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 28 times.\n",
      "[LOG]Number of events that ever occurred: 4015\n",
      "[LOG]Number of events that occurred for more than 28 times: 1168\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 9 times.\n",
      "[LOG]After one-hot encoding, number of feature: 1811\n",
      "[LOG]Among them, number of categorical feature: 997\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 1\n",
      "1119 01:14:08\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 28 times.\n",
      "[LOG]Number of events that ever occurred: 4015\n",
      "[LOG]Number of events that occurred for more than 28 times: 1168\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 9 times.\n",
      "[LOG]After one-hot encoding, number of feature: 1811\n",
      "[LOG]Among them, number of categorical feature: 997\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 2\n",
      "1119 01:29:39\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 28 times.\n",
      "[LOG]Number of events that ever occurred: 4015\n",
      "[LOG]Number of events that occurred for more than 28 times: 1168\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 9 times.\n",
      "[LOG]After one-hot encoding, number of feature: 1811\n",
      "[LOG]Among them, number of categorical feature: 997\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 3\n",
      "1119 01:44:22\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 28 times.\n",
      "[LOG]Number of events that ever occurred: 4015\n",
      "[LOG]Number of events that occurred for more than 28 times: 1168\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 9 times.\n",
      "[LOG]After one-hot encoding, number of feature: 1811\n",
      "[LOG]Among them, number of categorical feature: 997\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 4\n",
      "1119 01:58:47\n",
      "[LOG]Reading train&test csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2910: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 28 times.\n",
      "[LOG]Number of events that ever occurred: 4015\n",
      "[LOG]Number of events that occurred for more than 28 times: 1168\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 9 times.\n",
      "[LOG]After one-hot encoding, number of feature: 1811\n",
      "[LOG]Among them, number of categorical feature: 997\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n"
     ]
    }
   ],
   "source": [
    "dataset_idxs = [0, 1, 2] # 0: \"pancreatitis\", 1: \"ich\", 2: \"sepsis\"\n",
    "train_dfs, test_dfs, unique_times, dataset_names = load_val_data(dataset_idxs, verbose=True, data_path=\"../../dataset/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = [5, 10, 40, 70, 100, 130, 160, 190, 220]\n",
    "pca_flags = [True, False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For the pancreatitis dataset:\n",
      "KNN_results/KNN_P_0_1119_0304.pickle\n",
      "[LOG] n_neighbor = 5\n",
      "[LOG] avg. concordance: 0.5543624338624338\n",
      "[LOG] avg. ipec: 2.180587177749855 0.19433921206864846\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 10\n",
      "[LOG] avg. concordance: 0.5472481962481962\n",
      "[LOG] avg. ipec: 2.1236963838200524 0.1892689666874542\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 40\n",
      "[LOG] avg. concordance: 0.53749037999038\n",
      "[LOG] avg. ipec: 2.1114814245900093 0.1881803399283687\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 70\n",
      "[LOG] avg. concordance: 0.5507681577681578\n",
      "[LOG] avg. ipec: 2.0932337558304943 0.18655406348090595\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 100\n",
      "[LOG] avg. concordance: 0.5317727272727273\n",
      "[LOG] avg. ipec: 2.097486644883221 0.1869330912565233\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 130\n",
      "[LOG] avg. concordance: 0.5097462722462722\n",
      "[LOG] avg. ipec: 2.108682442627377 0.18793088787492057\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 160\n",
      "[LOG] avg. concordance: 0.5170757575757575\n",
      "[LOG] avg. ipec: 2.0986118054455485 0.187033368291702\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 190\n",
      "[LOG] avg. concordance: 0.5032032227032228\n",
      "[LOG] avg. ipec: 2.097399958962662 0.1869253655972739\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 220\n",
      "[LOG] avg. concordance: 0.5083232323232323\n",
      "[LOG] avg. ipec: 2.09340054571268 0.18656892819927892\n",
      "-------------------------------------------------------\n",
      "\n",
      "For the ich dataset:\n",
      "KNN_results/KNN_P_1_1119_0311.pickle\n",
      "[LOG] n_neighbor = 5\n",
      "[LOG] avg. concordance: 0.5599524805390961\n",
      "[LOG] avg. ipec: 1.6317947020510815 0.21001218816616235\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 10\n",
      "[LOG] avg. concordance: 0.5614220982920879\n",
      "[LOG] avg. ipec: 1.5118315524343497 0.19457291537121618\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 40\n",
      "[LOG] avg. concordance: 0.5662501452306262\n",
      "[LOG] avg. ipec: 1.4534280103565003 0.1870563719892536\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 70\n",
      "[LOG] avg. concordance: 0.5606090391541768\n",
      "[LOG] avg. ipec: 1.4510075229946824 0.1867448549542706\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 100\n",
      "[LOG] avg. concordance: 0.5641530149878007\n",
      "[LOG] avg. ipec: 1.445288386326863 0.1860088013290686\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 130\n",
      "[LOG] avg. concordance: 0.5639134425467642\n",
      "[LOG] avg. ipec: 1.4408331186652243 0.1854354078076222\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 160\n",
      "[LOG] avg. concordance: 0.5713465783664459\n",
      "[LOG] avg. ipec: 1.4378083895762241 0.18504612478458485\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 190\n",
      "[LOG] avg. concordance: 0.5699736261182758\n",
      "[LOG] avg. ipec: 1.4365076366538445 0.1848787177160675\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 220\n",
      "[LOG] avg. concordance: 0.5613918903218311\n",
      "[LOG] avg. ipec: 1.438856527767666 0.18518102030471892\n",
      "-------------------------------------------------------\n",
      "\n",
      "For the sepsis dataset:\n",
      "KNN_results/KNN_P_2_1119_0313.pickle\n",
      "[LOG] n_neighbor = 5\n",
      "[LOG] avg. concordance: 0.5683390478305999\n",
      "[LOG] avg. ipec: 2.3451217728355847 0.2051309652351952\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 10\n",
      "[LOG] avg. concordance: 0.5739773699176742\n",
      "[LOG] avg. ipec: 2.1952485747854626 0.1920213544102811\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 40\n",
      "[LOG] avg. concordance: 0.5873819305023124\n",
      "[LOG] avg. ipec: 2.074545734351178 0.18146331411927466\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 70\n",
      "[LOG] avg. concordance: 0.5872100349996818\n",
      "[LOG] avg. ipec: 2.065911825260891 0.1807080944432823\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 100\n",
      "[LOG] avg. concordance: 0.5866180465274101\n",
      "[LOG] avg. ipec: 2.067838266387615 0.18087660284756696\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 130\n",
      "[LOG] avg. concordance: 0.58640472935502\n",
      "[LOG] avg. ipec: 2.0715139178932573 0.18119811704352656\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 160\n",
      "[LOG] avg. concordance: 0.5868409789657735\n",
      "[LOG] avg. ipec: 2.0734447587474514 0.18136701029790858\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 190\n",
      "[LOG] avg. concordance: 0.5869394757741606\n",
      "[LOG] avg. ipec: 2.0764553253846336 0.18163034862316893\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 220\n",
      "[LOG] avg. concordance: 0.5857114469297651\n",
      "[LOG] avg. ipec: 2.080502107909264 0.18198432615004617\n",
      "-------------------------------------------------------\n",
      "\n",
      "For the pancreatitis dataset:\n",
      "KNN_results/KNN_0_1119_0412.pickle\n",
      "[LOG] n_neighbor = 5\n",
      "[LOG] avg. concordance: 0.5453044733044733\n",
      "[LOG] avg. ipec: 2.2702978390889332 0.20233444354422941\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 10\n",
      "[LOG] avg. concordance: 0.5453075998075998\n",
      "[LOG] avg. ipec: 2.17982397476421 0.19427119356959827\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 40\n",
      "[LOG] avg. concordance: 0.5339199134199134\n",
      "[LOG] avg. ipec: 2.114083035022768 0.18841220175291343\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 70\n",
      "[LOG] avg. concordance: 0.5307842712842713\n",
      "[LOG] avg. ipec: 2.1025942177628387 0.1873882905253883\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 100\n",
      "[LOG] avg. concordance: 0.50709139009139\n",
      "[LOG] avg. ipec: 2.1125095525273596 0.18827196918093386\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 130\n",
      "[LOG] avg. concordance: 0.507563492063492\n",
      "[LOG] avg. ipec: 2.0950555315377604 0.18671642454545243\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 160\n",
      "[LOG] avg. concordance: 0.516891774891775\n",
      "[LOG] avg. ipec: 2.090396167578981 0.18630117074146343\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 190\n",
      "[LOG] avg. concordance: 0.4996108706108706\n",
      "[LOG] avg. ipec: 2.0917221552109577 0.18641934597162188\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 220\n",
      "[LOG] avg. concordance: 0.5010930735930735\n",
      "[LOG] avg. ipec: 2.093491417082562 0.18657702687591182\n",
      "-------------------------------------------------------\n",
      "\n",
      "For the ich dataset:\n",
      "KNN_results/KNN_1_1119_0418.pickle\n",
      "[LOG] n_neighbor = 5\n",
      "[LOG] avg. concordance: 0.5674354595097014\n",
      "[LOG] avg. ipec: 1.64280146233152 0.21142875963082625\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 10\n",
      "[LOG] avg. concordance: 0.5628778900894621\n",
      "[LOG] avg. ipec: 1.5448254142353233 0.19881922963131574\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 40\n",
      "[LOG] avg. concordance: 0.5740228883466946\n",
      "[LOG] avg. ipec: 1.441157717323756 0.1854771836967511\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 70\n",
      "[LOG] avg. concordance: 0.569438945044731\n",
      "[LOG] avg. ipec: 1.4362981567550865 0.1848517576261373\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 100\n",
      "[LOG] avg. concordance: 0.5701839200650634\n",
      "[LOG] avg. ipec: 1.4340187244986848 0.18455839440137514\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 130\n",
      "[LOG] avg. concordance: 0.5746454049029859\n",
      "[LOG] avg. ipec: 1.432998766923986 0.18442712573024275\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 160\n",
      "[LOG] avg. concordance: 0.5739273846868829\n",
      "[LOG] avg. ipec: 1.4312404040670923 0.18420082420425898\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 190\n",
      "[LOG] avg. concordance: 0.5794636923434414\n",
      "[LOG] avg. ipec: 1.4336482317942152 0.18451071194262744\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 220\n",
      "[LOG] avg. concordance: 0.5774738003950273\n",
      "[LOG] avg. ipec: 1.4366456850491818 0.18489648456231428\n",
      "-------------------------------------------------------\n",
      "\n",
      "For the sepsis dataset:\n",
      "KNN_results/KNN_2_1119_0420.pickle\n",
      "[LOG] n_neighbor = 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] avg. concordance: 0.5479510259022279\n",
      "[LOG] avg. ipec: 2.413430160287936 0.21110599203937597\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 10\n",
      "[LOG] avg. concordance: 0.5556810443420666\n",
      "[LOG] avg. ipec: 2.2592503025272945 0.19761967187953886\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 40\n",
      "[LOG] avg. concordance: 0.5682394317888037\n",
      "[LOG] avg. ipec: 2.115272528762783 0.18502574177030717\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 70\n",
      "[LOG] avg. concordance: 0.5744061255331135\n",
      "[LOG] avg. ipec: 2.0980968325726232 0.18352336045310427\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 100\n",
      "[LOG] avg. concordance: 0.5754319612550054\n",
      "[LOG] avg. ipec: 2.096645256543156 0.1833963891395094\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 130\n",
      "[LOG] avg. concordance: 0.5751524014727492\n",
      "[LOG] avg. ipec: 2.098556976066052 0.1835636098252465\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 160\n",
      "[LOG] avg. concordance: 0.5759790062728257\n",
      "[LOG] avg. ipec: 2.0980513792534246 0.18351938458995365\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 190\n",
      "[LOG] avg. concordance: 0.5756347686342933\n",
      "[LOG] avg. ipec: 2.098600404498501 0.18356740856882142\n",
      "-------------------------------------------------------\n",
      "[LOG] n_neighbor = 220\n",
      "[LOG] avg. concordance: 0.574851822534181\n",
      "[LOG] avg. ipec: 2.099549224268315 0.18365040311412423\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for pca_flag in pca_flags:\n",
    "    for idx, dataset_name in enumerate(dataset_names):\n",
    "        sorted_unique_times = unique_times[dataset_name]\n",
    "        \n",
    "        filename = filename_generator(\"KNN\", pca_flag, [dataset_idxs[idx]])\n",
    "        concordances, ipecs = load_score_containers([dataset_name], [n_neighbors])\n",
    "        ipecs = {dataset_name: []}\n",
    "        print(\"\\nFor the \" + dataset_name + \" dataset:\")\n",
    "        print(filename)\n",
    "\n",
    "        for row, n_neighbor in enumerate(n_neighbors):\n",
    "            print(\"[LOG] n_neighbor = {}\".format(n_neighbor))\n",
    "\n",
    "            tmp_concordances = []\n",
    "            tmp_ipecs = []\n",
    "\n",
    "            for index, cur_train in enumerate(train_dfs[dataset_name]):\n",
    "                cur_test = test_dfs[dataset_name][index]\n",
    "                model = KNNKaplanMeier(n_neighbors=n_neighbor, \n",
    "                    pca_flag=pca_flag, n_components=20)\n",
    "                model.fit(cur_train, duration_col='LOS', event_col='OUT')\n",
    "                concordance, ipec_score_list = \\\n",
    "                    calc_scores(model, cur_test, sorted_unique_times,\n",
    "                                print_result=False, verbose_calc_time=False)\n",
    "\n",
    "                tmp_concordances.append(concordance)\n",
    "                tmp_ipecs.append(ipec_score_list)\n",
    "\n",
    "            avg_concordance = np.average(tmp_concordances)\n",
    "            avg_ipec = np.average(tmp_ipecs, axis=0)\n",
    "\n",
    "            print(\"[LOG] avg. concordance:\", avg_concordance)\n",
    "            print(\"[LOG] avg. ipec:\", \n",
    "                  avg_ipec[int(len(avg_ipec) * 0.8)], \n",
    "                  avg_ipec[int(len(avg_ipec) * 0.8)] / sorted_unique_times[int(len(avg_ipec) * 0.8)])\n",
    "\n",
    "            concordances[dataset_name][row] = avg_concordance\n",
    "            ipecs[dataset_name].append(avg_ipec)\n",
    "\n",
    "            print(\"-------------------------------------------------------\")\n",
    "\n",
    "            with open(filename, 'wb') as f:\n",
    "                pickle.dump([n_neighbors, concordances, ipecs], f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check IPEC Growth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = dataset_names[0]\n",
    "sorted_unique_times = unique_times[dataset_name]\n",
    "# T = sorted_unique_times[len(sorted_unique_times) - 1]\n",
    "# sorted_unique_times = list(np.arange(0, T, 0.1)) + [T]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116dca828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_neighbors = [5, 10, 50, 100, 160, 200]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "for n_neighbor in n_neighbors:\n",
    "    tmp_concordances = []\n",
    "    tmp_ipecs = []\n",
    "\n",
    "    for index, cur_train in enumerate(train_dfs[dataset_name]):\n",
    "        cur_test = test_dfs[dataset_name][index]\n",
    "        model = KNNKaplanMeier(n_neighbors=n_neighbor, \n",
    "            pca_flag=False, n_components=20)\n",
    "        model.fit(cur_train, duration_col='LOS', event_col='OUT')\n",
    "        concordance, ipec_score_list = \\\n",
    "            calc_scores(model, cur_test, sorted_unique_times,\n",
    "                        print_result=False, verbose_calc_time=False)\n",
    "\n",
    "        tmp_concordances.append(concordance)\n",
    "        tmp_ipecs.append(ipec_score_list)\n",
    "\n",
    "    avg_concordance = np.average(tmp_concordances)\n",
    "    avg_ipec = np.average(tmp_ipecs, axis=0)\n",
    "    \n",
    "    plt.plot(sorted_unique_times, avg_ipec, label=\"n_neighbor=\" + str(n_neighbor) + \", concordance=\" + str(avg_concordance))\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = dataset_names[2]\n",
    "sorted_unique_times = unique_times[dataset_name]\n",
    "# T = sorted_unique_times[len(sorted_unique_times) - 1]\n",
    "# sorted_unique_times = list(np.arange(0, T, 0.1)) + [T]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12d4d8518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_neighbors = [40, 70, 100, 160]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "for n_neighbor in n_neighbors:\n",
    "    tmp_concordances = []\n",
    "    tmp_ipecs = []\n",
    "\n",
    "    for index, cur_train in enumerate(train_dfs[dataset_name]):\n",
    "        cur_test = test_dfs[dataset_name][index]\n",
    "        model = KNNKaplanMeier(n_neighbors=n_neighbor, \n",
    "            pca_flag=False, n_components=20)\n",
    "        model.fit(cur_train, duration_col='LOS', event_col='OUT')\n",
    "        concordance, ipec_score_list = \\\n",
    "            calc_scores(model, cur_test, sorted_unique_times,\n",
    "                        print_result=False, verbose_calc_time=False)\n",
    "\n",
    "        tmp_concordances.append(concordance)\n",
    "        tmp_ipecs.append(ipec_score_list)\n",
    "\n",
    "    avg_concordance = np.average(tmp_concordances)\n",
    "    avg_ipec = np.average(tmp_ipecs, axis=0)\n",
    "    \n",
    "    plt.plot(sorted_unique_times, avg_ipec, label=\"n_neighbor=\" + str(n_neighbor) + \", concordance=\" + str(avg_concordance))\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18351938458995365"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_ipec[] / \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.432314814814815"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_unique_times[int(len(avg_ipec) * 0.8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras code for Cox proportional hazards survival layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_dfs[\"ich\"][0].drop(columns=[\"LOS\", \"OUT\"]).values\n",
    "y = train_dfs[\"ich\"][0][[\"LOS\", \"OUT\"]].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "x_standardized = standard_scaler.fit_transform(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02568274, 0.0896456 , 0.0268803 , ..., 0.0389889 , 0.02382653,\n",
       "        0.24523704],\n",
       "       [0.09809831, 0.1245616 , 0.08779401, ..., 0.09864418, 0.06324415,\n",
       "        0.34285599],\n",
       "       [0.02619975, 0.09172809, 0.02742056, ..., 0.03981628, 0.02436883,\n",
       "        0.24964897],\n",
       "       ...,\n",
       "       [0.03758335, 0.13619181, 0.03956533, ..., 0.0579648 , 0.03531566,\n",
       "        0.37115312],\n",
       "       [0.20538883, 0.23050988, 0.18611095, ..., 0.19580237, 0.1297861 ,\n",
       "        1.2       ],\n",
       "       [0.03156885, 0.09136989, 0.03061346, ..., 0.04515151, 0.02651382,\n",
       "        0.5       ]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4707469 , -0.47905082, -0.45439594, ..., -0.46133262,\n",
       "        -0.44610297, -0.31029787],\n",
       "       [-0.06411467, -0.26926576, -0.07271083, ..., -0.06816798,\n",
       "        -0.11507557, -0.16309386],\n",
       "       [-0.46784378, -0.46653858, -0.45101066, ..., -0.4558797 ,\n",
       "        -0.44154872, -0.30364492],\n",
       "       ...,\n",
       "       [-0.4039219 , -0.19938823, -0.37491156, ..., -0.33626989,\n",
       "        -0.34961776, -0.12042334],\n",
       "       [ 0.53834947,  0.36730104,  0.54334274, ...,  0.57216373,\n",
       "         0.44374073,  1.12943221],\n",
       "       [-0.43769485, -0.4686908 , -0.43100394, ..., -0.42071725,\n",
       "        -0.42353523,  0.07387067]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coxph_partial_log_likelihood_batch(y_true, y_pred, batch_size):\n",
    "    # y_pred in this context consists of each feature vector dotted with beta, with a 1 padded\n",
    "    y_observed_times = y_true[:, 0]\n",
    "    y_event_indicators = y_true[:, 1]\n",
    "    \n",
    "    R_batch = K.cast(K.greater_equal(K.repeat_elements(K.expand_dims(y_observed_times, axis=0), batch_size, 0),\n",
    "                                     K.repeat_elements(K.expand_dims(y_observed_times, axis=-1), batch_size, -1)),\n",
    "                     'float32')\n",
    "    \n",
    "    x_transpose_beta = y_pred[:, 0]\n",
    "    return -K.mean((x_transpose_beta\n",
    "                    - K.log(K.flatten(K.dot(R_batch,\n",
    "                                            K.expand_dims(K.exp(x_transpose_beta), axis=-1)))))\n",
    "                   * y_event_indicators)\n",
    "\n",
    "batch_size = len(x)  # yes, the code works even when batch size is not the full dataset\n",
    "coxph_partial_log_likelihood = lambda y_true, y_pred: coxph_partial_log_likelihood_batch(y_true, y_pred, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 32)                54624     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 32        \n",
      "_________________________________________________________________\n",
      "lambda_10 (Lambda)           (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 54,656\n",
      "Trainable params: 54,656\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2000\n",
      "606/606 [==============================] - 1s 949us/step - loss: 6.8921\n",
      "Epoch 2/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 12.0937\n",
      "Epoch 3/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 13.0344\n",
      "Epoch 4/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 11.4754\n",
      "Epoch 5/2000\n",
      "606/606 [==============================] - 0s 60us/step - loss: 9.3387\n",
      "Epoch 6/2000\n",
      "606/606 [==============================] - 0s 46us/step - loss: 7.7134\n",
      "Epoch 7/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 8.9003\n",
      "Epoch 8/2000\n",
      "606/606 [==============================] - 0s 30us/step - loss: 9.1391\n",
      "Epoch 9/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 7.1936\n",
      "Epoch 10/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 6.9242\n",
      "Epoch 11/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 7.1072\n",
      "Epoch 12/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 7.1649\n",
      "Epoch 13/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 6.9979\n",
      "Epoch 14/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 6.6273\n",
      "Epoch 15/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 6.4690\n",
      "Epoch 16/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 6.5249\n",
      "Epoch 17/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 6.4139\n",
      "Epoch 18/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 6.6154\n",
      "Epoch 19/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 6.5813\n",
      "Epoch 20/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 6.3406\n",
      "Epoch 21/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 6.0719\n",
      "Epoch 22/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 6.6341\n",
      "Epoch 23/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 6.0133\n",
      "Epoch 24/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 6.2921\n",
      "Epoch 25/2000\n",
      "606/606 [==============================] - 0s 29us/step - loss: 6.3808\n",
      "Epoch 26/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 6.2345\n",
      "Epoch 27/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 5.9157\n",
      "Epoch 28/2000\n",
      "606/606 [==============================] - 0s 29us/step - loss: 5.7765\n",
      "Epoch 29/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 6.1387\n",
      "Epoch 30/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 5.7450\n",
      "Epoch 31/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 6.0083\n",
      "Epoch 32/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 6.1041\n",
      "Epoch 33/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 5.9912\n",
      "Epoch 34/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 5.7441\n",
      "Epoch 35/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 5.6142\n",
      "Epoch 36/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 6.0220\n",
      "Epoch 37/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 5.5940\n",
      "Epoch 38/2000\n",
      "606/606 [==============================] - 0s 28us/step - loss: 5.6693\n",
      "Epoch 39/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 5.7853\n",
      "Epoch 40/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 5.7693\n",
      "Epoch 41/2000\n",
      "606/606 [==============================] - 0s 29us/step - loss: 5.6328\n",
      "Epoch 42/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 5.5310\n",
      "Epoch 43/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 5.7016\n",
      "Epoch 44/2000\n",
      "606/606 [==============================] - 0s 29us/step - loss: 5.5299\n",
      "Epoch 45/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 5.5116\n",
      "Epoch 46/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 5.5793\n",
      "Epoch 47/2000\n",
      "606/606 [==============================] - 0s 29us/step - loss: 5.5503\n",
      "Epoch 48/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 5.4499\n",
      "Epoch 49/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 5.4928\n",
      "Epoch 50/2000\n",
      "606/606 [==============================] - 0s 28us/step - loss: 5.4678\n",
      "Epoch 51/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 5.4181\n",
      "Epoch 52/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 5.4670\n",
      "Epoch 53/2000\n",
      "606/606 [==============================] - 0s 30us/step - loss: 5.4315\n",
      "Epoch 54/2000\n",
      "606/606 [==============================] - 0s 29us/step - loss: 5.3763\n",
      "Epoch 55/2000\n",
      "606/606 [==============================] - 0s 46us/step - loss: 5.4431\n",
      "Epoch 56/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 5.3579\n",
      "Epoch 57/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 5.3896\n",
      "Epoch 58/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 5.3791\n",
      "Epoch 59/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 5.3324\n",
      "Epoch 60/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 5.3674\n",
      "Epoch 61/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 5.3200\n",
      "Epoch 62/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 5.3262\n",
      "Epoch 63/2000\n",
      "606/606 [==============================] - 0s 29us/step - loss: 5.3282\n",
      "Epoch 64/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 5.2980\n",
      "Epoch 65/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 5.3075\n",
      "Epoch 66/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 5.2915\n",
      "Epoch 67/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 5.2807\n",
      "Epoch 68/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 5.2854\n",
      "Epoch 69/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 5.2657\n",
      "Epoch 70/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 5.2641\n",
      "Epoch 71/2000\n",
      "606/606 [==============================] - 0s 28us/step - loss: 5.2582\n",
      "Epoch 72/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 5.2457\n",
      "Epoch 73/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 5.2479\n",
      "Epoch 74/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 5.2335\n",
      "Epoch 75/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 5.2314\n",
      "Epoch 76/2000\n",
      "606/606 [==============================] - 0s 29us/step - loss: 5.2244\n",
      "Epoch 77/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 5.2164\n",
      "Epoch 78/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 5.2154\n",
      "Epoch 79/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 5.2041\n",
      "Epoch 80/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 5.2036\n",
      "Epoch 81/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 5.1944\n",
      "Epoch 82/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 5.1907\n",
      "Epoch 83/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 5.1859\n",
      "Epoch 84/2000\n",
      "606/606 [==============================] - 0s 28us/step - loss: 5.1784\n",
      "Epoch 85/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 5.1765\n",
      "Epoch 86/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 5.1684\n",
      "Epoch 87/2000\n",
      "606/606 [==============================] - 0s 29us/step - loss: 5.1661\n",
      "Epoch 88/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 5.1597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 5.1557\n",
      "Epoch 90/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 5.1512\n",
      "Epoch 91/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 5.1461\n",
      "Epoch 92/2000\n",
      "606/606 [==============================] - 0s 30us/step - loss: 5.1428\n",
      "Epoch 93/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 5.1372\n",
      "Epoch 94/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 5.1344\n",
      "Epoch 95/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 5.1291\n",
      "Epoch 96/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 5.1259\n",
      "Epoch 97/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 5.1214\n",
      "Epoch 98/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 5.1177\n",
      "Epoch 99/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 5.1140\n",
      "Epoch 100/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 5.1100\n",
      "Epoch 101/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 5.1068\n",
      "Epoch 102/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 5.1027\n",
      "Epoch 103/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 5.0997\n",
      "Epoch 104/2000\n",
      "606/606 [==============================] - 0s 46us/step - loss: 5.0958\n",
      "Epoch 105/2000\n",
      "606/606 [==============================] - 0s 48us/step - loss: 5.0929\n",
      "Epoch 106/2000\n",
      "606/606 [==============================] - 0s 46us/step - loss: 5.0892\n",
      "Epoch 107/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 5.0863\n",
      "Epoch 108/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 5.0829\n",
      "Epoch 109/2000\n",
      "606/606 [==============================] - 0s 29us/step - loss: 5.0799\n",
      "Epoch 110/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 5.0768\n",
      "Epoch 111/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 5.0739\n",
      "Epoch 112/2000\n",
      "606/606 [==============================] - 0s 30us/step - loss: 5.0709\n",
      "Epoch 113/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 5.0681\n",
      "Epoch 114/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 5.0653\n",
      "Epoch 115/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 5.0625\n",
      "Epoch 116/2000\n",
      "606/606 [==============================] - 0s 30us/step - loss: 5.0599\n",
      "Epoch 117/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 5.0572\n",
      "Epoch 118/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 5.0547\n",
      "Epoch 119/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 5.0520\n",
      "Epoch 120/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 5.0496\n",
      "Epoch 121/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 5.0471\n",
      "Epoch 122/2000\n",
      "606/606 [==============================] - 0s 30us/step - loss: 5.0448\n",
      "Epoch 123/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 5.0424\n",
      "Epoch 124/2000\n",
      "606/606 [==============================] - 0s 29us/step - loss: 5.0401\n",
      "Epoch 125/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 5.0378\n",
      "Epoch 126/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 5.0356\n",
      "Epoch 127/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 5.0334\n",
      "Epoch 128/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 5.0313\n",
      "Epoch 129/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 5.0291\n",
      "Epoch 130/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 5.0271\n",
      "Epoch 131/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 5.0250\n",
      "Epoch 132/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 5.0231\n",
      "Epoch 133/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 5.0211\n",
      "Epoch 134/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 5.0191\n",
      "Epoch 135/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 5.0172\n",
      "Epoch 136/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 5.0153\n",
      "Epoch 137/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 5.0135\n",
      "Epoch 138/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 5.0116\n",
      "Epoch 139/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 5.0098\n",
      "Epoch 140/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 5.0080\n",
      "Epoch 141/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 5.0063\n",
      "Epoch 142/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 5.0045\n",
      "Epoch 143/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 5.0028\n",
      "Epoch 144/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 5.0011\n",
      "Epoch 145/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.9994\n",
      "Epoch 146/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.9978\n",
      "Epoch 147/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.9961\n",
      "Epoch 148/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.9945\n",
      "Epoch 149/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.9929\n",
      "Epoch 150/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.9913\n",
      "Epoch 151/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.9898\n",
      "Epoch 152/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.9882\n",
      "Epoch 153/2000\n",
      "606/606 [==============================] - 0s 30us/step - loss: 4.9867\n",
      "Epoch 154/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.9852\n",
      "Epoch 155/2000\n",
      "606/606 [==============================] - 0s 30us/step - loss: 4.9837\n",
      "Epoch 156/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.9822\n",
      "Epoch 157/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.9807\n",
      "Epoch 158/2000\n",
      "606/606 [==============================] - 0s 30us/step - loss: 4.9792\n",
      "Epoch 159/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.9778\n",
      "Epoch 160/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.9763\n",
      "Epoch 161/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.9749\n",
      "Epoch 162/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.9735\n",
      "Epoch 163/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.9721\n",
      "Epoch 164/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.9707\n",
      "Epoch 165/2000\n",
      "606/606 [==============================] - 0s 29us/step - loss: 4.9694\n",
      "Epoch 166/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.9680\n",
      "Epoch 167/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.9666\n",
      "Epoch 168/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.9653\n",
      "Epoch 169/2000\n",
      "606/606 [==============================] - 0s 30us/step - loss: 4.9639\n",
      "Epoch 170/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.9626\n",
      "Epoch 171/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.9613\n",
      "Epoch 172/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.9600\n",
      "Epoch 173/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.9587\n",
      "Epoch 174/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.9574\n",
      "Epoch 175/2000\n",
      "606/606 [==============================] - 0s 30us/step - loss: 4.9561\n",
      "Epoch 176/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.9549\n",
      "Epoch 177/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.9536\n",
      "Epoch 178/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.9523\n",
      "Epoch 179/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.9511\n",
      "Epoch 180/2000\n",
      "606/606 [==============================] - 0s 28us/step - loss: 4.9498\n",
      "Epoch 181/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.9486\n",
      "Epoch 182/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.9474\n",
      "Epoch 183/2000\n",
      "606/606 [==============================] - 0s 29us/step - loss: 4.9462\n",
      "Epoch 184/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.9450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185/2000\n",
      "606/606 [==============================] - 0s 29us/step - loss: 4.9438\n",
      "Epoch 186/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.9426\n",
      "Epoch 187/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.9414\n",
      "Epoch 188/2000\n",
      "606/606 [==============================] - 0s 29us/step - loss: 4.9402\n",
      "Epoch 189/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.9390\n",
      "Epoch 190/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.9379\n",
      "Epoch 191/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.9367\n",
      "Epoch 192/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.9355\n",
      "Epoch 193/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.9344\n",
      "Epoch 194/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.9332\n",
      "Epoch 195/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.9321\n",
      "Epoch 196/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.9310\n",
      "Epoch 197/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.9298\n",
      "Epoch 198/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.9287\n",
      "Epoch 199/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.9276\n",
      "Epoch 200/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.9265\n",
      "Epoch 201/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.9254\n",
      "Epoch 202/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.9243\n",
      "Epoch 203/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.9232\n",
      "Epoch 204/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.9221\n",
      "Epoch 205/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.9210\n",
      "Epoch 206/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.9199\n",
      "Epoch 207/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.9188\n",
      "Epoch 208/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.9178\n",
      "Epoch 209/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.9167\n",
      "Epoch 210/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.9156\n",
      "Epoch 211/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.9146\n",
      "Epoch 212/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.9135\n",
      "Epoch 213/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.9125\n",
      "Epoch 214/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.9114\n",
      "Epoch 215/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.9104\n",
      "Epoch 216/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.9094\n",
      "Epoch 217/2000\n",
      "606/606 [==============================] - 0s 30us/step - loss: 4.9083\n",
      "Epoch 218/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.9073\n",
      "Epoch 219/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.9063\n",
      "Epoch 220/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.9053\n",
      "Epoch 221/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.9042\n",
      "Epoch 222/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.9032\n",
      "Epoch 223/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.9022\n",
      "Epoch 224/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.9012\n",
      "Epoch 225/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.9002\n",
      "Epoch 226/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.8992\n",
      "Epoch 227/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.8982\n",
      "Epoch 228/2000\n",
      "606/606 [==============================] - 0s 30us/step - loss: 4.8972\n",
      "Epoch 229/2000\n",
      "606/606 [==============================] - 0s 28us/step - loss: 4.8962\n",
      "Epoch 230/2000\n",
      "606/606 [==============================] - 0s 28us/step - loss: 4.8953\n",
      "Epoch 231/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.8943\n",
      "Epoch 232/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.8933\n",
      "Epoch 233/2000\n",
      "606/606 [==============================] - 0s 51us/step - loss: 4.8923\n",
      "Epoch 234/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.8914\n",
      "Epoch 235/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.8904\n",
      "Epoch 236/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8895\n",
      "Epoch 237/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.8885\n",
      "Epoch 238/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.8875\n",
      "Epoch 239/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8866\n",
      "Epoch 240/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8857\n",
      "Epoch 241/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.8847\n",
      "Epoch 242/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.8838\n",
      "Epoch 243/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.8828\n",
      "Epoch 244/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.8819\n",
      "Epoch 245/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8810\n",
      "Epoch 246/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.8800\n",
      "Epoch 247/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.8791\n",
      "Epoch 248/2000\n",
      "606/606 [==============================] - 0s 30us/step - loss: 4.8782\n",
      "Epoch 249/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.8773\n",
      "Epoch 250/2000\n",
      "606/606 [==============================] - 0s 29us/step - loss: 4.8764\n",
      "Epoch 251/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.8755\n",
      "Epoch 252/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.8746\n",
      "Epoch 253/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.8737\n",
      "Epoch 254/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.8728\n",
      "Epoch 255/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.8719\n",
      "Epoch 256/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.8710\n",
      "Epoch 257/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8701\n",
      "Epoch 258/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.8692\n",
      "Epoch 259/2000\n",
      "606/606 [==============================] - 0s 29us/step - loss: 4.8683\n",
      "Epoch 260/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.8674\n",
      "Epoch 261/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.8666\n",
      "Epoch 262/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.8657\n",
      "Epoch 263/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.8648\n",
      "Epoch 264/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.8640\n",
      "Epoch 265/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.8631\n",
      "Epoch 266/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8622\n",
      "Epoch 267/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.8614\n",
      "Epoch 268/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.8605\n",
      "Epoch 269/2000\n",
      "606/606 [==============================] - 0s 29us/step - loss: 4.8597\n",
      "Epoch 270/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.8588\n",
      "Epoch 271/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.8580\n",
      "Epoch 272/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.8571\n",
      "Epoch 273/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.8563\n",
      "Epoch 274/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.8555\n",
      "Epoch 275/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.8546\n",
      "Epoch 276/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.8538\n",
      "Epoch 277/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8530\n",
      "Epoch 278/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.8521\n",
      "Epoch 279/2000\n",
      "606/606 [==============================] - 0s 29us/step - loss: 4.8513\n",
      "Epoch 280/2000\n",
      "606/606 [==============================] - 0s 29us/step - loss: 4.8505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.8497\n",
      "Epoch 282/2000\n",
      "606/606 [==============================] - 0s 30us/step - loss: 4.8489\n",
      "Epoch 283/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.8481\n",
      "Epoch 284/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.8473\n",
      "Epoch 285/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.8465\n",
      "Epoch 286/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.8457\n",
      "Epoch 287/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.8449\n",
      "Epoch 288/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.8441\n",
      "Epoch 289/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.8433\n",
      "Epoch 290/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8425\n",
      "Epoch 291/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.8417\n",
      "Epoch 292/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.8409\n",
      "Epoch 293/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.8401\n",
      "Epoch 294/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.8393\n",
      "Epoch 295/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.8386\n",
      "Epoch 296/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.8378\n",
      "Epoch 297/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.8370\n",
      "Epoch 298/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.8363\n",
      "Epoch 299/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.8355\n",
      "Epoch 300/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.8347\n",
      "Epoch 301/2000\n",
      "606/606 [==============================] - 0s 30us/step - loss: 4.8340\n",
      "Epoch 302/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.8332\n",
      "Epoch 303/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.8324\n",
      "Epoch 304/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.8317\n",
      "Epoch 305/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.8309\n",
      "Epoch 306/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.8302\n",
      "Epoch 307/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.8294\n",
      "Epoch 308/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.8287\n",
      "Epoch 309/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.8279\n",
      "Epoch 310/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.8272\n",
      "Epoch 311/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.8265\n",
      "Epoch 312/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.8257\n",
      "Epoch 313/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.8250\n",
      "Epoch 314/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.8243\n",
      "Epoch 315/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.8235\n",
      "Epoch 316/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.8228\n",
      "Epoch 317/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.8221\n",
      "Epoch 318/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.8214\n",
      "Epoch 319/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.8206\n",
      "Epoch 320/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.8199\n",
      "Epoch 321/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.8192\n",
      "Epoch 322/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.8185\n",
      "Epoch 323/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.8178\n",
      "Epoch 324/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.8171\n",
      "Epoch 325/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.8163\n",
      "Epoch 326/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.8156\n",
      "Epoch 327/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.8149\n",
      "Epoch 328/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.8142\n",
      "Epoch 329/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.8135\n",
      "Epoch 330/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.8128\n",
      "Epoch 331/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.8121\n",
      "Epoch 332/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.8114\n",
      "Epoch 333/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.8108\n",
      "Epoch 334/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.8101\n",
      "Epoch 335/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.8094\n",
      "Epoch 336/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.8087\n",
      "Epoch 337/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.8080\n",
      "Epoch 338/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.8073\n",
      "Epoch 339/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.8066\n",
      "Epoch 340/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.8060\n",
      "Epoch 341/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.8053\n",
      "Epoch 342/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8046\n",
      "Epoch 343/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.8039\n",
      "Epoch 344/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8033\n",
      "Epoch 345/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.8026\n",
      "Epoch 346/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.8019\n",
      "Epoch 347/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8013\n",
      "Epoch 348/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.8006\n",
      "Epoch 349/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7999\n",
      "Epoch 350/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7993\n",
      "Epoch 351/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7986\n",
      "Epoch 352/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7980\n",
      "Epoch 353/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7973\n",
      "Epoch 354/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7967\n",
      "Epoch 355/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7960\n",
      "Epoch 356/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7954\n",
      "Epoch 357/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7947\n",
      "Epoch 358/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7941\n",
      "Epoch 359/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7934\n",
      "Epoch 360/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7928\n",
      "Epoch 361/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7922\n",
      "Epoch 362/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7915\n",
      "Epoch 363/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7909\n",
      "Epoch 364/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7903\n",
      "Epoch 365/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7896\n",
      "Epoch 366/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7890\n",
      "Epoch 367/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7884\n",
      "Epoch 368/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7877\n",
      "Epoch 369/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7871\n",
      "Epoch 370/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7865\n",
      "Epoch 371/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7859\n",
      "Epoch 372/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.7852\n",
      "Epoch 373/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7846\n",
      "Epoch 374/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7840\n",
      "Epoch 375/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7834\n",
      "Epoch 376/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 377/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7822\n",
      "Epoch 378/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7816\n",
      "Epoch 379/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7809\n",
      "Epoch 380/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7803\n",
      "Epoch 381/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7797\n",
      "Epoch 382/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7791\n",
      "Epoch 383/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7785\n",
      "Epoch 384/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.7779\n",
      "Epoch 385/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.7773\n",
      "Epoch 386/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.7767\n",
      "Epoch 387/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.7761\n",
      "Epoch 388/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.7755\n",
      "Epoch 389/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7750\n",
      "Epoch 390/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7744\n",
      "Epoch 391/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7739\n",
      "Epoch 392/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.7734\n",
      "Epoch 393/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7733\n",
      "Epoch 394/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7736\n",
      "Epoch 395/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.7761\n",
      "Epoch 396/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7800\n",
      "Epoch 397/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.8002\n",
      "Epoch 398/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7961\n",
      "Epoch 399/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8388\n",
      "Epoch 400/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 4.7794\n",
      "Epoch 401/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7697\n",
      "Epoch 402/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7831\n",
      "Epoch 403/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7956\n",
      "Epoch 404/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8573\n",
      "Epoch 405/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7716\n",
      "Epoch 406/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7900\n",
      "Epoch 407/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.9275\n",
      "Epoch 408/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7653\n",
      "Epoch 409/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 5.0915\n",
      "Epoch 410/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 6.2956\n",
      "Epoch 411/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 6.8353\n",
      "Epoch 412/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 5.7898\n",
      "Epoch 413/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 5.2640\n",
      "Epoch 414/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 6.6724\n",
      "Epoch 415/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 6.4510\n",
      "Epoch 416/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 8.4199\n",
      "Epoch 417/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 9.0014\n",
      "Epoch 418/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 8.2112\n",
      "Epoch 419/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 6.7423\n",
      "Epoch 420/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 5.9044\n",
      "Epoch 421/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 8.8459\n",
      "Epoch 422/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 5.8126\n",
      "Epoch 423/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 6.8822\n",
      "Epoch 424/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 7.7453\n",
      "Epoch 425/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 7.7707\n",
      "Epoch 426/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 6.9832\n",
      "Epoch 427/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 7.0529\n",
      "Epoch 428/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 5.7317\n",
      "Epoch 429/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 5.4790\n",
      "Epoch 430/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 5.5212\n",
      "Epoch 431/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 5.9078\n",
      "Epoch 432/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 5.5754\n",
      "Epoch 433/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 6.1758\n",
      "Epoch 434/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 6.0368\n",
      "Epoch 435/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 5.5022\n",
      "Epoch 436/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 6.8649\n",
      "Epoch 437/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 7.2232\n",
      "Epoch 438/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 8.8793\n",
      "Epoch 439/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 8.9428\n",
      "Epoch 440/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 8.0745\n",
      "Epoch 441/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 7.0497\n",
      "Epoch 442/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 6.4593\n",
      "Epoch 443/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 7.1480\n",
      "Epoch 444/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 7.7924\n",
      "Epoch 445/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 6.4286\n",
      "Epoch 446/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 6.0604\n",
      "Epoch 447/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 6.3346\n",
      "Epoch 448/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 6.4960\n",
      "Epoch 449/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 6.3209\n",
      "Epoch 450/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 5.8409\n",
      "Epoch 451/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 5.4482\n",
      "Epoch 452/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 7.1352\n",
      "Epoch 453/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 5.8413\n",
      "Epoch 454/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 6.9158\n",
      "Epoch 455/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 7.4334\n",
      "Epoch 456/2000\n",
      "606/606 [==============================] - 0s 48us/step - loss: 7.2050\n",
      "Epoch 457/2000\n",
      "606/606 [==============================] - 0s 47us/step - loss: 6.4004\n",
      "Epoch 458/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 5.6581\n",
      "Epoch 459/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 9.4686\n",
      "Epoch 460/2000\n",
      "606/606 [==============================] - 0s 45us/step - loss: 6.2794\n",
      "Epoch 461/2000\n",
      "606/606 [==============================] - 0s 46us/step - loss: 7.5953\n",
      "Epoch 462/2000\n",
      "606/606 [==============================] - 0s 53us/step - loss: 8.3690\n",
      "Epoch 463/2000\n",
      "606/606 [==============================] - 0s 56us/step - loss: 8.4716\n",
      "Epoch 464/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 8.0483\n",
      "Epoch 465/2000\n",
      "606/606 [==============================] - 0s 50us/step - loss: 7.3406\n",
      "Epoch 466/2000\n",
      "606/606 [==============================] - 0s 51us/step - loss: 6.6243\n",
      "Epoch 467/2000\n",
      "606/606 [==============================] - 0s 47us/step - loss: 6.3541\n",
      "Epoch 468/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 7.0164\n",
      "Epoch 469/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 7.2818\n",
      "Epoch 470/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 6.3242\n",
      "Epoch 471/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 6.0954\n",
      "Epoch 472/2000\n",
      "606/606 [==============================] - 0s 52us/step - loss: 6.2782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 473/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 6.4388\n",
      "Epoch 474/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 6.4243\n",
      "Epoch 475/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 6.2119\n",
      "Epoch 476/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 5.8638\n",
      "Epoch 477/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 5.5349\n",
      "Epoch 478/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 5.5393\n",
      "Epoch 479/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 5.8953\n",
      "Epoch 480/2000\n",
      "606/606 [==============================] - 0s 50us/step - loss: 5.2884\n",
      "Epoch 481/2000\n",
      "606/606 [==============================] - 0s 45us/step - loss: 5.3438\n",
      "Epoch 482/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 5.5389\n",
      "Epoch 483/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 5.5465\n",
      "Epoch 484/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 5.3140\n",
      "Epoch 485/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 5.1193\n",
      "Epoch 486/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 5.6367\n",
      "Epoch 487/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 5.1257\n",
      "Epoch 488/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 5.3950\n",
      "Epoch 489/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 5.4450\n",
      "Epoch 490/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 5.2394\n",
      "Epoch 491/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 5.0356\n",
      "Epoch 492/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 5.2706\n",
      "Epoch 493/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 5.1236\n",
      "Epoch 494/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 5.0241\n",
      "Epoch 495/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 5.1208\n",
      "Epoch 496/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 5.1533\n",
      "Epoch 497/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 5.0803\n",
      "Epoch 498/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.9897\n",
      "Epoch 499/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 5.0392\n",
      "Epoch 500/2000\n",
      "606/606 [==============================] - 0s 53us/step - loss: 5.0709\n",
      "Epoch 501/2000\n",
      "606/606 [==============================] - 0s 56us/step - loss: 4.9599\n",
      "Epoch 502/2000\n",
      "606/606 [==============================] - 0s 52us/step - loss: 4.9865\n",
      "Epoch 503/2000\n",
      "606/606 [==============================] - 0s 46us/step - loss: 5.0198\n",
      "Epoch 504/2000\n",
      "606/606 [==============================] - 0s 52us/step - loss: 4.9788\n",
      "Epoch 505/2000\n",
      "606/606 [==============================] - 0s 46us/step - loss: 4.9195\n",
      "Epoch 506/2000\n",
      "606/606 [==============================] - 0s 49us/step - loss: 4.9682\n",
      "Epoch 507/2000\n",
      "606/606 [==============================] - 0s 53us/step - loss: 4.9405\n",
      "Epoch 508/2000\n",
      "606/606 [==============================] - 0s 54us/step - loss: 4.9074\n",
      "Epoch 509/2000\n",
      "606/606 [==============================] - 0s 46us/step - loss: 4.9443\n",
      "Epoch 510/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.9308\n",
      "Epoch 511/2000\n",
      "606/606 [==============================] - 0s 50us/step - loss: 4.8947\n",
      "Epoch 512/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.9305\n",
      "Epoch 513/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.8988\n",
      "Epoch 514/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.8921\n",
      "Epoch 515/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.9066\n",
      "Epoch 516/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.8840\n",
      "Epoch 517/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.8755\n",
      "Epoch 518/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8900\n",
      "Epoch 519/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8667\n",
      "Epoch 520/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8719\n",
      "Epoch 521/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.8753\n",
      "Epoch 522/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.8611\n",
      "Epoch 523/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.8624\n",
      "Epoch 524/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.8653\n",
      "Epoch 525/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.8534\n",
      "Epoch 526/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.8568\n",
      "Epoch 527/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.8563\n",
      "Epoch 528/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.8478\n",
      "Epoch 529/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.8499\n",
      "Epoch 530/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.8484\n",
      "Epoch 531/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.8423\n",
      "Epoch 532/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.8447\n",
      "Epoch 533/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.8418\n",
      "Epoch 534/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.8378\n",
      "Epoch 535/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.8401\n",
      "Epoch 536/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.8362\n",
      "Epoch 537/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8351\n",
      "Epoch 538/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.8358\n",
      "Epoch 539/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.8323\n",
      "Epoch 540/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.8321\n",
      "Epoch 541/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8314\n",
      "Epoch 542/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.8287\n",
      "Epoch 543/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.8290\n",
      "Epoch 544/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.8273\n",
      "Epoch 545/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.8258\n",
      "Epoch 546/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8259\n",
      "Epoch 547/2000\n",
      "606/606 [==============================] - 0s 46us/step - loss: 4.8241\n",
      "Epoch 548/2000\n",
      "606/606 [==============================] - 0s 45us/step - loss: 4.8235\n",
      "Epoch 549/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 4.8230\n",
      "Epoch 550/2000\n",
      "606/606 [==============================] - 0s 51us/step - loss: 4.8214\n",
      "Epoch 551/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.8211\n",
      "Epoch 552/2000\n",
      "606/606 [==============================] - 0s 45us/step - loss: 4.8202\n",
      "Epoch 553/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8189\n",
      "Epoch 554/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.8186\n",
      "Epoch 555/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8175\n",
      "Epoch 556/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.8167\n",
      "Epoch 557/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.8162\n",
      "Epoch 558/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.8151\n",
      "Epoch 559/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.8146\n",
      "Epoch 560/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.8139\n",
      "Epoch 561/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.8130\n",
      "Epoch 562/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.8126\n",
      "Epoch 563/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.8117\n",
      "Epoch 564/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.8111\n",
      "Epoch 565/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.8105\n",
      "Epoch 566/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8097\n",
      "Epoch 567/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.8092\n",
      "Epoch 568/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 569/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.8078\n",
      "Epoch 570/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.8073\n",
      "Epoch 571/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8066\n",
      "Epoch 572/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.8061\n",
      "Epoch 573/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.8055\n",
      "Epoch 574/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.8048\n",
      "Epoch 575/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8043\n",
      "Epoch 576/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.8037\n",
      "Epoch 577/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.8031\n",
      "Epoch 578/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.8026\n",
      "Epoch 579/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.8020\n",
      "Epoch 580/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8015\n",
      "Epoch 581/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.8009\n",
      "Epoch 582/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.8004\n",
      "Epoch 583/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7998\n",
      "Epoch 584/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7993\n",
      "Epoch 585/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7988\n",
      "Epoch 586/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7982\n",
      "Epoch 587/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7977\n",
      "Epoch 588/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7972\n",
      "Epoch 589/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7967\n",
      "Epoch 590/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7962\n",
      "Epoch 591/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.7957\n",
      "Epoch 592/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7952\n",
      "Epoch 593/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7947\n",
      "Epoch 594/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7942\n",
      "Epoch 595/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7937\n",
      "Epoch 596/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7932\n",
      "Epoch 597/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7927\n",
      "Epoch 598/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7922\n",
      "Epoch 599/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.7918\n",
      "Epoch 600/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.7913\n",
      "Epoch 601/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7908\n",
      "Epoch 602/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7903\n",
      "Epoch 603/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7899\n",
      "Epoch 604/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7894\n",
      "Epoch 605/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7889\n",
      "Epoch 606/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7885\n",
      "Epoch 607/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7880\n",
      "Epoch 608/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7875\n",
      "Epoch 609/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7871\n",
      "Epoch 610/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7866\n",
      "Epoch 611/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7862\n",
      "Epoch 612/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7857\n",
      "Epoch 613/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7853\n",
      "Epoch 614/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7848\n",
      "Epoch 615/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7844\n",
      "Epoch 616/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.7839\n",
      "Epoch 617/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7835\n",
      "Epoch 618/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7830\n",
      "Epoch 619/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7826\n",
      "Epoch 620/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7822\n",
      "Epoch 621/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7817\n",
      "Epoch 622/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7813\n",
      "Epoch 623/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7808\n",
      "Epoch 624/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7804\n",
      "Epoch 625/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7800\n",
      "Epoch 626/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7795\n",
      "Epoch 627/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7791\n",
      "Epoch 628/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7787\n",
      "Epoch 629/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7783\n",
      "Epoch 630/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7778\n",
      "Epoch 631/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7774\n",
      "Epoch 632/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7770\n",
      "Epoch 633/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7765\n",
      "Epoch 634/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7761\n",
      "Epoch 635/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7757\n",
      "Epoch 636/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7753\n",
      "Epoch 637/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.7749\n",
      "Epoch 638/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7744\n",
      "Epoch 639/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7740\n",
      "Epoch 640/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7736\n",
      "Epoch 641/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7732\n",
      "Epoch 642/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7728\n",
      "Epoch 643/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7723\n",
      "Epoch 644/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7719\n",
      "Epoch 645/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7715\n",
      "Epoch 646/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7711\n",
      "Epoch 647/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7707\n",
      "Epoch 648/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7703\n",
      "Epoch 649/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7699\n",
      "Epoch 650/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7694\n",
      "Epoch 651/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7690\n",
      "Epoch 652/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7686\n",
      "Epoch 653/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.7682\n",
      "Epoch 654/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7678\n",
      "Epoch 655/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7674\n",
      "Epoch 656/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7670\n",
      "Epoch 657/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.7666\n",
      "Epoch 658/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7662\n",
      "Epoch 659/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7658\n",
      "Epoch 660/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7654\n",
      "Epoch 661/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7650\n",
      "Epoch 662/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7646\n",
      "Epoch 663/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7642\n",
      "Epoch 664/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.7638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 665/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7634\n",
      "Epoch 666/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7629\n",
      "Epoch 667/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7626\n",
      "Epoch 668/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7621\n",
      "Epoch 669/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.7617\n",
      "Epoch 670/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.7614\n",
      "Epoch 671/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7610\n",
      "Epoch 672/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.7606\n",
      "Epoch 673/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7602\n",
      "Epoch 674/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7598\n",
      "Epoch 675/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7594\n",
      "Epoch 676/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7590\n",
      "Epoch 677/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7586\n",
      "Epoch 678/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7582\n",
      "Epoch 679/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7578\n",
      "Epoch 680/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7574\n",
      "Epoch 681/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.7570\n",
      "Epoch 682/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7566\n",
      "Epoch 683/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.7562\n",
      "Epoch 684/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7558\n",
      "Epoch 685/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7554\n",
      "Epoch 686/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7550\n",
      "Epoch 687/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7546\n",
      "Epoch 688/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.7542\n",
      "Epoch 689/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7538\n",
      "Epoch 690/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7534\n",
      "Epoch 691/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7530\n",
      "Epoch 692/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7527\n",
      "Epoch 693/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7523\n",
      "Epoch 694/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7519\n",
      "Epoch 695/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7515\n",
      "Epoch 696/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7511\n",
      "Epoch 697/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7507\n",
      "Epoch 698/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7503\n",
      "Epoch 699/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7499\n",
      "Epoch 700/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7495\n",
      "Epoch 701/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7491\n",
      "Epoch 702/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7488\n",
      "Epoch 703/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7484\n",
      "Epoch 704/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.7480\n",
      "Epoch 705/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7476\n",
      "Epoch 706/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7472\n",
      "Epoch 707/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7468\n",
      "Epoch 708/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7464\n",
      "Epoch 709/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7461\n",
      "Epoch 710/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7457\n",
      "Epoch 711/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7453\n",
      "Epoch 712/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7449\n",
      "Epoch 713/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7445\n",
      "Epoch 714/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7441\n",
      "Epoch 715/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7438\n",
      "Epoch 716/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7434\n",
      "Epoch 717/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7430\n",
      "Epoch 718/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7426\n",
      "Epoch 719/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7423\n",
      "Epoch 720/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7419\n",
      "Epoch 721/2000\n",
      "606/606 [==============================] - 0s 45us/step - loss: 4.7415\n",
      "Epoch 722/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7411\n",
      "Epoch 723/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7408\n",
      "Epoch 724/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7404\n",
      "Epoch 725/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7400\n",
      "Epoch 726/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7396\n",
      "Epoch 727/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7393\n",
      "Epoch 728/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7389\n",
      "Epoch 729/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7385\n",
      "Epoch 730/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7382\n",
      "Epoch 731/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7378\n",
      "Epoch 732/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7374\n",
      "Epoch 733/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7371\n",
      "Epoch 734/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7367\n",
      "Epoch 735/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7363\n",
      "Epoch 736/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7360\n",
      "Epoch 737/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7356\n",
      "Epoch 738/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7353\n",
      "Epoch 739/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7349\n",
      "Epoch 740/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.7346\n",
      "Epoch 741/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7342\n",
      "Epoch 742/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7339\n",
      "Epoch 743/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7335\n",
      "Epoch 744/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7332\n",
      "Epoch 745/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7328\n",
      "Epoch 746/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.7325\n",
      "Epoch 747/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7322\n",
      "Epoch 748/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7318\n",
      "Epoch 749/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7315\n",
      "Epoch 750/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.7312\n",
      "Epoch 751/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7308\n",
      "Epoch 752/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7305\n",
      "Epoch 753/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7302\n",
      "Epoch 754/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7299\n",
      "Epoch 755/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.7296\n",
      "Epoch 756/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7292\n",
      "Epoch 757/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.7289\n",
      "Epoch 758/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.7286\n",
      "Epoch 759/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7283\n",
      "Epoch 760/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 761/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7277\n",
      "Epoch 762/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7274\n",
      "Epoch 763/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.7271\n",
      "Epoch 764/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7268\n",
      "Epoch 765/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7265\n",
      "Epoch 766/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 4.7262\n",
      "Epoch 767/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7259\n",
      "Epoch 768/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.7256\n",
      "Epoch 769/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7254\n",
      "Epoch 770/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7251\n",
      "Epoch 771/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7248\n",
      "Epoch 772/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7245\n",
      "Epoch 773/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7242\n",
      "Epoch 774/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7239\n",
      "Epoch 775/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7237\n",
      "Epoch 776/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7234\n",
      "Epoch 777/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7231\n",
      "Epoch 778/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7228\n",
      "Epoch 779/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7226\n",
      "Epoch 780/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7223\n",
      "Epoch 781/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7220\n",
      "Epoch 782/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7217\n",
      "Epoch 783/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7215\n",
      "Epoch 784/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7212\n",
      "Epoch 785/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7209\n",
      "Epoch 786/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7207\n",
      "Epoch 787/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7204\n",
      "Epoch 788/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7201\n",
      "Epoch 789/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.7199\n",
      "Epoch 790/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7196\n",
      "Epoch 791/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7193\n",
      "Epoch 792/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7191\n",
      "Epoch 793/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7188\n",
      "Epoch 794/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7185\n",
      "Epoch 795/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.7183\n",
      "Epoch 796/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7180\n",
      "Epoch 797/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7177\n",
      "Epoch 798/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7175\n",
      "Epoch 799/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7172\n",
      "Epoch 800/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7170\n",
      "Epoch 801/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7167\n",
      "Epoch 802/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7164\n",
      "Epoch 803/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7162\n",
      "Epoch 804/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7159\n",
      "Epoch 805/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7156\n",
      "Epoch 806/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7154\n",
      "Epoch 807/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7151\n",
      "Epoch 808/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7149\n",
      "Epoch 809/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7146\n",
      "Epoch 810/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7143\n",
      "Epoch 811/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7141\n",
      "Epoch 812/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7138\n",
      "Epoch 813/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7136\n",
      "Epoch 814/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7133\n",
      "Epoch 815/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7130\n",
      "Epoch 816/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7128\n",
      "Epoch 817/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7125\n",
      "Epoch 818/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7123\n",
      "Epoch 819/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7120\n",
      "Epoch 820/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7118\n",
      "Epoch 821/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7115\n",
      "Epoch 822/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7112\n",
      "Epoch 823/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7110\n",
      "Epoch 824/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7107\n",
      "Epoch 825/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7105\n",
      "Epoch 826/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7102\n",
      "Epoch 827/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.7100\n",
      "Epoch 828/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7097\n",
      "Epoch 829/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7095\n",
      "Epoch 830/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7092\n",
      "Epoch 831/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7089\n",
      "Epoch 832/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7087\n",
      "Epoch 833/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.7084\n",
      "Epoch 834/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7082\n",
      "Epoch 835/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7079\n",
      "Epoch 836/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7077\n",
      "Epoch 837/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7074\n",
      "Epoch 838/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7072\n",
      "Epoch 839/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7069\n",
      "Epoch 840/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7067\n",
      "Epoch 841/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.7064\n",
      "Epoch 842/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7062\n",
      "Epoch 843/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7059\n",
      "Epoch 844/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7057\n",
      "Epoch 845/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7054\n",
      "Epoch 846/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7051\n",
      "Epoch 847/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7049\n",
      "Epoch 848/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7046\n",
      "Epoch 849/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7044\n",
      "Epoch 850/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7041\n",
      "Epoch 851/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7039\n",
      "Epoch 852/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.7036\n",
      "Epoch 853/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7034\n",
      "Epoch 854/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7031\n",
      "Epoch 855/2000\n",
      "606/606 [==============================] - 0s 45us/step - loss: 4.7029\n",
      "Epoch 856/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.7026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 857/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7024\n",
      "Epoch 858/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.7021\n",
      "Epoch 859/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7019\n",
      "Epoch 860/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7016\n",
      "Epoch 861/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.7014\n",
      "Epoch 862/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7011\n",
      "Epoch 863/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7009\n",
      "Epoch 864/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7006\n",
      "Epoch 865/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.7004\n",
      "Epoch 866/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.7001\n",
      "Epoch 867/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6999\n",
      "Epoch 868/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6996\n",
      "Epoch 869/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6994\n",
      "Epoch 870/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6992\n",
      "Epoch 871/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6989\n",
      "Epoch 872/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6987\n",
      "Epoch 873/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6984\n",
      "Epoch 874/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6982\n",
      "Epoch 875/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6979\n",
      "Epoch 876/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6977\n",
      "Epoch 877/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6974\n",
      "Epoch 878/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6972\n",
      "Epoch 879/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6969\n",
      "Epoch 880/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6967\n",
      "Epoch 881/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6964\n",
      "Epoch 882/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6962\n",
      "Epoch 883/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.6960\n",
      "Epoch 884/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.6957\n",
      "Epoch 885/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6955\n",
      "Epoch 886/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6952\n",
      "Epoch 887/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6950\n",
      "Epoch 888/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6947\n",
      "Epoch 889/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6945\n",
      "Epoch 890/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6942\n",
      "Epoch 891/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6940\n",
      "Epoch 892/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6937\n",
      "Epoch 893/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6935\n",
      "Epoch 894/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6933\n",
      "Epoch 895/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6930\n",
      "Epoch 896/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6928\n",
      "Epoch 897/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6925\n",
      "Epoch 898/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6923\n",
      "Epoch 899/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6920\n",
      "Epoch 900/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6918\n",
      "Epoch 901/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6916\n",
      "Epoch 902/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6913\n",
      "Epoch 903/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6911\n",
      "Epoch 904/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6908\n",
      "Epoch 905/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6906\n",
      "Epoch 906/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6903\n",
      "Epoch 907/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6901\n",
      "Epoch 908/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6899\n",
      "Epoch 909/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6896\n",
      "Epoch 910/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6894\n",
      "Epoch 911/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6891\n",
      "Epoch 912/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6889\n",
      "Epoch 913/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6887\n",
      "Epoch 914/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6884\n",
      "Epoch 915/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6882\n",
      "Epoch 916/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6879\n",
      "Epoch 917/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6877\n",
      "Epoch 918/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6874\n",
      "Epoch 919/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6872\n",
      "Epoch 920/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6870\n",
      "Epoch 921/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6867\n",
      "Epoch 922/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6865\n",
      "Epoch 923/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6862\n",
      "Epoch 924/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6860\n",
      "Epoch 925/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6858\n",
      "Epoch 926/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6855\n",
      "Epoch 927/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6853\n",
      "Epoch 928/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.6850\n",
      "Epoch 929/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6848\n",
      "Epoch 930/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6846\n",
      "Epoch 931/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6843\n",
      "Epoch 932/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6841\n",
      "Epoch 933/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6838\n",
      "Epoch 934/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.6836\n",
      "Epoch 935/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6834\n",
      "Epoch 936/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.6831\n",
      "Epoch 937/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6829\n",
      "Epoch 938/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6827\n",
      "Epoch 939/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6824\n",
      "Epoch 940/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6822\n",
      "Epoch 941/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6819\n",
      "Epoch 942/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6817\n",
      "Epoch 943/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.6815\n",
      "Epoch 944/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6812\n",
      "Epoch 945/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6810\n",
      "Epoch 946/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6808\n",
      "Epoch 947/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6805\n",
      "Epoch 948/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6803\n",
      "Epoch 949/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6801\n",
      "Epoch 950/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6798\n",
      "Epoch 951/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6796\n",
      "Epoch 952/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.6793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 953/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6791\n",
      "Epoch 954/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6789\n",
      "Epoch 955/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6786\n",
      "Epoch 956/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6784\n",
      "Epoch 957/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6782\n",
      "Epoch 958/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6779\n",
      "Epoch 959/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6777\n",
      "Epoch 960/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6775\n",
      "Epoch 961/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6772\n",
      "Epoch 962/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6770\n",
      "Epoch 963/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6768\n",
      "Epoch 964/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6765\n",
      "Epoch 965/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6763\n",
      "Epoch 966/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6761\n",
      "Epoch 967/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6758\n",
      "Epoch 968/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6756\n",
      "Epoch 969/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6754\n",
      "Epoch 970/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6751\n",
      "Epoch 971/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6749\n",
      "Epoch 972/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6746\n",
      "Epoch 973/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6744\n",
      "Epoch 974/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6742\n",
      "Epoch 975/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6739\n",
      "Epoch 976/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6737\n",
      "Epoch 977/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6735\n",
      "Epoch 978/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6732\n",
      "Epoch 979/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6730\n",
      "Epoch 980/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6728\n",
      "Epoch 981/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6725\n",
      "Epoch 982/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 4.6723\n",
      "Epoch 983/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6721\n",
      "Epoch 984/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6718\n",
      "Epoch 985/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6716\n",
      "Epoch 986/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6714\n",
      "Epoch 987/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6712\n",
      "Epoch 988/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6709\n",
      "Epoch 989/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6707\n",
      "Epoch 990/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6705\n",
      "Epoch 991/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6702\n",
      "Epoch 992/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6700\n",
      "Epoch 993/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6698\n",
      "Epoch 994/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6695\n",
      "Epoch 995/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6693\n",
      "Epoch 996/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6691\n",
      "Epoch 997/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6688\n",
      "Epoch 998/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6686\n",
      "Epoch 999/2000\n",
      "606/606 [==============================] - 0s 54us/step - loss: 4.6684\n",
      "Epoch 1000/2000\n",
      "606/606 [==============================] - 0s 49us/step - loss: 4.6682\n",
      "Epoch 1001/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6679\n",
      "Epoch 1002/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.6677\n",
      "Epoch 1003/2000\n",
      "606/606 [==============================] - 0s 46us/step - loss: 4.6675\n",
      "Epoch 1004/2000\n",
      "606/606 [==============================] - 0s 45us/step - loss: 4.6672\n",
      "Epoch 1005/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 4.6670\n",
      "Epoch 1006/2000\n",
      "606/606 [==============================] - 0s 48us/step - loss: 4.6668\n",
      "Epoch 1007/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6665\n",
      "Epoch 1008/2000\n",
      "606/606 [==============================] - 0s 49us/step - loss: 4.6663\n",
      "Epoch 1009/2000\n",
      "606/606 [==============================] - 0s 47us/step - loss: 4.6661\n",
      "Epoch 1010/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6659\n",
      "Epoch 1011/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6656\n",
      "Epoch 1012/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6654\n",
      "Epoch 1013/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6652\n",
      "Epoch 1014/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6649\n",
      "Epoch 1015/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6647\n",
      "Epoch 1016/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6645\n",
      "Epoch 1017/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6643\n",
      "Epoch 1018/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6640\n",
      "Epoch 1019/2000\n",
      "606/606 [==============================] - 0s 47us/step - loss: 4.6638\n",
      "Epoch 1020/2000\n",
      "606/606 [==============================] - 0s 46us/step - loss: 4.6636\n",
      "Epoch 1021/2000\n",
      "606/606 [==============================] - 0s 49us/step - loss: 4.6633\n",
      "Epoch 1022/2000\n",
      "606/606 [==============================] - 0s 52us/step - loss: 4.6631\n",
      "Epoch 1023/2000\n",
      "606/606 [==============================] - 0s 48us/step - loss: 4.6629\n",
      "Epoch 1024/2000\n",
      "606/606 [==============================] - 0s 53us/step - loss: 4.6627\n",
      "Epoch 1025/2000\n",
      "606/606 [==============================] - 0s 50us/step - loss: 4.6624\n",
      "Epoch 1026/2000\n",
      "606/606 [==============================] - 0s 52us/step - loss: 4.6622\n",
      "Epoch 1027/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.6620\n",
      "Epoch 1028/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.6618\n",
      "Epoch 1029/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.6615\n",
      "Epoch 1030/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6613\n",
      "Epoch 1031/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6611\n",
      "Epoch 1032/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6608\n",
      "Epoch 1033/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6606\n",
      "Epoch 1034/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6604\n",
      "Epoch 1035/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6602\n",
      "Epoch 1036/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6599\n",
      "Epoch 1037/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6597\n",
      "Epoch 1038/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6595\n",
      "Epoch 1039/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6593\n",
      "Epoch 1040/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6590\n",
      "Epoch 1041/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6588\n",
      "Epoch 1042/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6586\n",
      "Epoch 1043/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6584\n",
      "Epoch 1044/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.6581\n",
      "Epoch 1045/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6579\n",
      "Epoch 1046/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6577\n",
      "Epoch 1047/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1048/2000\n",
      "606/606 [==============================] - 0s 53us/step - loss: 4.6572\n",
      "Epoch 1049/2000\n",
      "606/606 [==============================] - 0s 48us/step - loss: 4.6570\n",
      "Epoch 1050/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6568\n",
      "Epoch 1051/2000\n",
      "606/606 [==============================] - 0s 52us/step - loss: 4.6566\n",
      "Epoch 1052/2000\n",
      "606/606 [==============================] - 0s 48us/step - loss: 4.6563\n",
      "Epoch 1053/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.6561\n",
      "Epoch 1054/2000\n",
      "606/606 [==============================] - 0s 53us/step - loss: 4.6559\n",
      "Epoch 1055/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.6557\n",
      "Epoch 1056/2000\n",
      "606/606 [==============================] - 0s 55us/step - loss: 4.6554\n",
      "Epoch 1057/2000\n",
      "606/606 [==============================] - 0s 53us/step - loss: 4.6552\n",
      "Epoch 1058/2000\n",
      "606/606 [==============================] - 0s 48us/step - loss: 4.6550\n",
      "Epoch 1059/2000\n",
      "606/606 [==============================] - 0s 56us/step - loss: 4.6548\n",
      "Epoch 1060/2000\n",
      "606/606 [==============================] - 0s 49us/step - loss: 4.6545\n",
      "Epoch 1061/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6543\n",
      "Epoch 1062/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6541\n",
      "Epoch 1063/2000\n",
      "606/606 [==============================] - 0s 46us/step - loss: 4.6539\n",
      "Epoch 1064/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6537\n",
      "Epoch 1065/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6534\n",
      "Epoch 1066/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6532\n",
      "Epoch 1067/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6530\n",
      "Epoch 1068/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.6528\n",
      "Epoch 1069/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6525\n",
      "Epoch 1070/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6523\n",
      "Epoch 1071/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6521\n",
      "Epoch 1072/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.6519\n",
      "Epoch 1073/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6517\n",
      "Epoch 1074/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6514\n",
      "Epoch 1075/2000\n",
      "606/606 [==============================] - 0s 52us/step - loss: 4.6512\n",
      "Epoch 1076/2000\n",
      "606/606 [==============================] - 0s 50us/step - loss: 4.6510\n",
      "Epoch 1077/2000\n",
      "606/606 [==============================] - 0s 52us/step - loss: 4.6508\n",
      "Epoch 1078/2000\n",
      "606/606 [==============================] - 0s 53us/step - loss: 4.6506\n",
      "Epoch 1079/2000\n",
      "606/606 [==============================] - 0s 56us/step - loss: 4.6503\n",
      "Epoch 1080/2000\n",
      "606/606 [==============================] - 0s 53us/step - loss: 4.6501\n",
      "Epoch 1081/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 4.6499\n",
      "Epoch 1082/2000\n",
      "606/606 [==============================] - 0s 52us/step - loss: 4.6497\n",
      "Epoch 1083/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6494\n",
      "Epoch 1084/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6492\n",
      "Epoch 1085/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6490\n",
      "Epoch 1086/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6488\n",
      "Epoch 1087/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6486\n",
      "Epoch 1088/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6483\n",
      "Epoch 1089/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6481\n",
      "Epoch 1090/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6479\n",
      "Epoch 1091/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6477\n",
      "Epoch 1092/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6475\n",
      "Epoch 1093/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6472\n",
      "Epoch 1094/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6470\n",
      "Epoch 1095/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6468\n",
      "Epoch 1096/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6466\n",
      "Epoch 1097/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6464\n",
      "Epoch 1098/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6462\n",
      "Epoch 1099/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6459\n",
      "Epoch 1100/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6457\n",
      "Epoch 1101/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6455\n",
      "Epoch 1102/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.6453\n",
      "Epoch 1103/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.6451\n",
      "Epoch 1104/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.6448\n",
      "Epoch 1105/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.6446\n",
      "Epoch 1106/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6444\n",
      "Epoch 1107/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6442\n",
      "Epoch 1108/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.6440\n",
      "Epoch 1109/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6438\n",
      "Epoch 1110/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6435\n",
      "Epoch 1111/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6433\n",
      "Epoch 1112/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6431\n",
      "Epoch 1113/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6429\n",
      "Epoch 1114/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6427\n",
      "Epoch 1115/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6425\n",
      "Epoch 1116/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6422\n",
      "Epoch 1117/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6420\n",
      "Epoch 1118/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6418\n",
      "Epoch 1119/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6416\n",
      "Epoch 1120/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6414\n",
      "Epoch 1121/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6412\n",
      "Epoch 1122/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6409\n",
      "Epoch 1123/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6407\n",
      "Epoch 1124/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6405\n",
      "Epoch 1125/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6403\n",
      "Epoch 1126/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6401\n",
      "Epoch 1127/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6399\n",
      "Epoch 1128/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.6396\n",
      "Epoch 1129/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6394\n",
      "Epoch 1130/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6392\n",
      "Epoch 1131/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6390\n",
      "Epoch 1132/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6388\n",
      "Epoch 1133/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6386\n",
      "Epoch 1134/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6384\n",
      "Epoch 1135/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6382\n",
      "Epoch 1136/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6379\n",
      "Epoch 1137/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.6377\n",
      "Epoch 1138/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6375\n",
      "Epoch 1139/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6373\n",
      "Epoch 1140/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6371\n",
      "Epoch 1141/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6369\n",
      "Epoch 1142/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606/606 [==============================] - 0s 36us/step - loss: 4.6366\n",
      "Epoch 1143/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.6364\n",
      "Epoch 1144/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6362\n",
      "Epoch 1145/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6360\n",
      "Epoch 1146/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.6358\n",
      "Epoch 1147/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6356\n",
      "Epoch 1148/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6354\n",
      "Epoch 1149/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6352\n",
      "Epoch 1150/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6349\n",
      "Epoch 1151/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6347\n",
      "Epoch 1152/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6345\n",
      "Epoch 1153/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6343\n",
      "Epoch 1154/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6341\n",
      "Epoch 1155/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6339\n",
      "Epoch 1156/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6337\n",
      "Epoch 1157/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6335\n",
      "Epoch 1158/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6332\n",
      "Epoch 1159/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6330\n",
      "Epoch 1160/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6328\n",
      "Epoch 1161/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6326\n",
      "Epoch 1162/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6324\n",
      "Epoch 1163/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6322\n",
      "Epoch 1164/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6320\n",
      "Epoch 1165/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6318\n",
      "Epoch 1166/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6316\n",
      "Epoch 1167/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6313\n",
      "Epoch 1168/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6311\n",
      "Epoch 1169/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6309\n",
      "Epoch 1170/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6307\n",
      "Epoch 1171/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6305\n",
      "Epoch 1172/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.6303\n",
      "Epoch 1173/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6301\n",
      "Epoch 1174/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6299\n",
      "Epoch 1175/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6297\n",
      "Epoch 1176/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6295\n",
      "Epoch 1177/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6293\n",
      "Epoch 1178/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6290\n",
      "Epoch 1179/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6288\n",
      "Epoch 1180/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.6286\n",
      "Epoch 1181/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6284\n",
      "Epoch 1182/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6282\n",
      "Epoch 1183/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6280\n",
      "Epoch 1184/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6278\n",
      "Epoch 1185/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6276\n",
      "Epoch 1186/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6274\n",
      "Epoch 1187/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6272\n",
      "Epoch 1188/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6270\n",
      "Epoch 1189/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6267\n",
      "Epoch 1190/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6265\n",
      "Epoch 1191/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6263\n",
      "Epoch 1192/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6261\n",
      "Epoch 1193/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6259\n",
      "Epoch 1194/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6257\n",
      "Epoch 1195/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6255\n",
      "Epoch 1196/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6253\n",
      "Epoch 1197/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6251\n",
      "Epoch 1198/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6249\n",
      "Epoch 1199/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6247\n",
      "Epoch 1200/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6245\n",
      "Epoch 1201/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6243\n",
      "Epoch 1202/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6241\n",
      "Epoch 1203/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6238\n",
      "Epoch 1204/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6236\n",
      "Epoch 1205/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6234\n",
      "Epoch 1206/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6232\n",
      "Epoch 1207/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6230\n",
      "Epoch 1208/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6228\n",
      "Epoch 1209/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6226\n",
      "Epoch 1210/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6224\n",
      "Epoch 1211/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6222\n",
      "Epoch 1212/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6220\n",
      "Epoch 1213/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6218\n",
      "Epoch 1214/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6216\n",
      "Epoch 1215/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6214\n",
      "Epoch 1216/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6212\n",
      "Epoch 1217/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6210\n",
      "Epoch 1218/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6208\n",
      "Epoch 1219/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.6206\n",
      "Epoch 1220/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6204\n",
      "Epoch 1221/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6202\n",
      "Epoch 1222/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6200\n",
      "Epoch 1223/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6198\n",
      "Epoch 1224/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6196\n",
      "Epoch 1225/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6194\n",
      "Epoch 1226/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6192\n",
      "Epoch 1227/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6191\n",
      "Epoch 1228/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6192\n",
      "Epoch 1229/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6195\n",
      "Epoch 1230/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6203\n",
      "Epoch 1231/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6234\n",
      "Epoch 1232/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6265\n",
      "Epoch 1233/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6418\n",
      "Epoch 1234/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6379\n",
      "Epoch 1235/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6634\n",
      "Epoch 1236/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1237/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6222\n",
      "Epoch 1238/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6177\n",
      "Epoch 1239/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6183\n",
      "Epoch 1240/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6239\n",
      "Epoch 1241/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6307\n",
      "Epoch 1242/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6647\n",
      "Epoch 1243/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6429\n",
      "Epoch 1244/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6694\n",
      "Epoch 1245/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 4.6282\n",
      "Epoch 1246/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6186\n",
      "Epoch 1247/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.6165\n",
      "Epoch 1248/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.6205\n",
      "Epoch 1249/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.6337\n",
      "Epoch 1250/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6348\n",
      "Epoch 1251/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6688\n",
      "Epoch 1252/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6336\n",
      "Epoch 1253/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6348\n",
      "Epoch 1254/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6232\n",
      "Epoch 1255/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6240\n",
      "Epoch 1256/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6205\n",
      "Epoch 1257/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6238\n",
      "Epoch 1258/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6224\n",
      "Epoch 1259/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.6320\n",
      "Epoch 1260/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6297\n",
      "Epoch 1261/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6543\n",
      "Epoch 1262/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.6336\n",
      "Epoch 1263/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.6473\n",
      "Epoch 1264/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6256\n",
      "Epoch 1265/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6240\n",
      "Epoch 1266/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6172\n",
      "Epoch 1267/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6159\n",
      "Epoch 1268/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6144\n",
      "Epoch 1269/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.6161\n",
      "Epoch 1270/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6190\n",
      "Epoch 1271/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6374\n",
      "Epoch 1272/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6448\n",
      "Epoch 1273/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7361\n",
      "Epoch 1274/2000\n",
      "606/606 [==============================] - 0s 53us/step - loss: 4.6153\n",
      "Epoch 1275/2000\n",
      "606/606 [==============================] - 0s 49us/step - loss: 4.6741\n",
      "Epoch 1276/2000\n",
      "606/606 [==============================] - 0s 45us/step - loss: 4.9613\n",
      "Epoch 1277/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.7507\n",
      "Epoch 1278/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 5.6453\n",
      "Epoch 1279/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 7.3985\n",
      "Epoch 1280/2000\n",
      "606/606 [==============================] - 0s 53us/step - loss: 9.2980\n",
      "Epoch 1281/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 8.6422\n",
      "Epoch 1282/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 7.2163\n",
      "Epoch 1283/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 6.7266\n",
      "Epoch 1284/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 7.6653\n",
      "Epoch 1285/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 6.5921\n",
      "Epoch 1286/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 5.6992\n",
      "Epoch 1287/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 6.2891\n",
      "Epoch 1288/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 6.3271\n",
      "Epoch 1289/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 5.5870\n",
      "Epoch 1290/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 6.5494\n",
      "Epoch 1291/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 7.0010\n",
      "Epoch 1292/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 9.0368\n",
      "Epoch 1293/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 9.2068\n",
      "Epoch 1294/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 7.8217\n",
      "Epoch 1295/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 6.0745\n",
      "Epoch 1296/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 14.7696\n",
      "Epoch 1297/2000\n",
      "606/606 [==============================] - 0s 51us/step - loss: 6.7507\n",
      "Epoch 1298/2000\n",
      "606/606 [==============================] - 0s 55us/step - loss: 8.5342\n",
      "Epoch 1299/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 9.5441\n",
      "Epoch 1300/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 9.7032\n",
      "Epoch 1301/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 9.1750\n",
      "Epoch 1302/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 8.2456\n",
      "Epoch 1303/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 7.3432\n",
      "Epoch 1304/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 7.1081\n",
      "Epoch 1305/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 7.9138\n",
      "Epoch 1306/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 7.9022\n",
      "Epoch 1307/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 6.6641\n",
      "Epoch 1308/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 6.2322\n",
      "Epoch 1309/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 6.3963\n",
      "Epoch 1310/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 6.5462\n",
      "Epoch 1311/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 6.4266\n",
      "Epoch 1312/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 5.9936\n",
      "Epoch 1313/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 5.4817\n",
      "Epoch 1314/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 5.5375\n",
      "Epoch 1315/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 5.8973\n",
      "Epoch 1316/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 5.1468\n",
      "Epoch 1317/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 5.6384\n",
      "Epoch 1318/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 5.6922\n",
      "Epoch 1319/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 5.1924\n",
      "Epoch 1320/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 5.3680\n",
      "Epoch 1321/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.9762\n",
      "Epoch 1322/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 5.0580\n",
      "Epoch 1323/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 5.0957\n",
      "Epoch 1324/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 5.0042\n",
      "Epoch 1325/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.9637\n",
      "Epoch 1326/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 5.0569\n",
      "Epoch 1327/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.9466\n",
      "Epoch 1328/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.9524\n",
      "Epoch 1329/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.9774\n",
      "Epoch 1330/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.9279\n",
      "Epoch 1331/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606/606 [==============================] - 0s 37us/step - loss: 4.8746\n",
      "Epoch 1332/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.9215\n",
      "Epoch 1333/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.8521\n",
      "Epoch 1334/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.8556\n",
      "Epoch 1335/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.8690\n",
      "Epoch 1336/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.8257\n",
      "Epoch 1337/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.8407\n",
      "Epoch 1338/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.8273\n",
      "Epoch 1339/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.8161\n",
      "Epoch 1340/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.8307\n",
      "Epoch 1341/2000\n",
      "606/606 [==============================] - 0s 56us/step - loss: 4.8004\n",
      "Epoch 1342/2000\n",
      "606/606 [==============================] - 0s 55us/step - loss: 4.8121\n",
      "Epoch 1343/2000\n",
      "606/606 [==============================] - 0s 57us/step - loss: 4.7926\n",
      "Epoch 1344/2000\n",
      "606/606 [==============================] - 0s 52us/step - loss: 4.7875\n",
      "Epoch 1345/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.7897\n",
      "Epoch 1346/2000\n",
      "606/606 [==============================] - 0s 53us/step - loss: 4.7707\n",
      "Epoch 1347/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 4.7778\n",
      "Epoch 1348/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.7669\n",
      "Epoch 1349/2000\n",
      "606/606 [==============================] - 0s 50us/step - loss: 4.7633\n",
      "Epoch 1350/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 4.7658\n",
      "Epoch 1351/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7548\n",
      "Epoch 1352/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.7565\n",
      "Epoch 1353/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.7521\n",
      "Epoch 1354/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7461\n",
      "Epoch 1355/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.7476\n",
      "Epoch 1356/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.7401\n",
      "Epoch 1357/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.7392\n",
      "Epoch 1358/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7368\n",
      "Epoch 1359/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.7322\n",
      "Epoch 1360/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7330\n",
      "Epoch 1361/2000\n",
      "606/606 [==============================] - 0s 54us/step - loss: 4.7281\n",
      "Epoch 1362/2000\n",
      "606/606 [==============================] - 0s 54us/step - loss: 4.7280\n",
      "Epoch 1363/2000\n",
      "606/606 [==============================] - 0s 50us/step - loss: 4.7254\n",
      "Epoch 1364/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7230\n",
      "Epoch 1365/2000\n",
      "606/606 [==============================] - 0s 49us/step - loss: 4.7224\n",
      "Epoch 1366/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.7187\n",
      "Epoch 1367/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.7185\n",
      "Epoch 1368/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.7155\n",
      "Epoch 1369/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.7143\n",
      "Epoch 1370/2000\n",
      "606/606 [==============================] - 0s 54us/step - loss: 4.7131\n",
      "Epoch 1371/2000\n",
      "606/606 [==============================] - 0s 48us/step - loss: 4.7108\n",
      "Epoch 1372/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.7104\n",
      "Epoch 1373/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 4.7082\n",
      "Epoch 1374/2000\n",
      "606/606 [==============================] - 0s 51us/step - loss: 4.7074\n",
      "Epoch 1375/2000\n",
      "606/606 [==============================] - 0s 53us/step - loss: 4.7059\n",
      "Epoch 1376/2000\n",
      "606/606 [==============================] - 0s 53us/step - loss: 4.7043\n",
      "Epoch 1377/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.7035\n",
      "Epoch 1378/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.7017\n",
      "Epoch 1379/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.7009\n",
      "Epoch 1380/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6995\n",
      "Epoch 1381/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6984\n",
      "Epoch 1382/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6974\n",
      "Epoch 1383/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6961\n",
      "Epoch 1384/2000\n",
      "606/606 [==============================] - 0s 51us/step - loss: 4.6953\n",
      "Epoch 1385/2000\n",
      "606/606 [==============================] - 0s 45us/step - loss: 4.6939\n",
      "Epoch 1386/2000\n",
      "606/606 [==============================] - 0s 53us/step - loss: 4.6931\n",
      "Epoch 1387/2000\n",
      "606/606 [==============================] - 0s 55us/step - loss: 4.6919\n",
      "Epoch 1388/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 4.6909\n",
      "Epoch 1389/2000\n",
      "606/606 [==============================] - 0s 54us/step - loss: 4.6899\n",
      "Epoch 1390/2000\n",
      "606/606 [==============================] - 0s 50us/step - loss: 4.6888\n",
      "Epoch 1391/2000\n",
      "606/606 [==============================] - 0s 51us/step - loss: 4.6879\n",
      "Epoch 1392/2000\n",
      "606/606 [==============================] - 0s 55us/step - loss: 4.6868\n",
      "Epoch 1393/2000\n",
      "606/606 [==============================] - 0s 54us/step - loss: 4.6860\n",
      "Epoch 1394/2000\n",
      "606/606 [==============================] - 0s 50us/step - loss: 4.6850\n",
      "Epoch 1395/2000\n",
      "606/606 [==============================] - 0s 55us/step - loss: 4.6841\n",
      "Epoch 1396/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6832\n",
      "Epoch 1397/2000\n",
      "606/606 [==============================] - 0s 45us/step - loss: 4.6823\n",
      "Epoch 1398/2000\n",
      "606/606 [==============================] - 0s 48us/step - loss: 4.6815\n",
      "Epoch 1399/2000\n",
      "606/606 [==============================] - 0s 50us/step - loss: 4.6805\n",
      "Epoch 1400/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.6797\n",
      "Epoch 1401/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6788\n",
      "Epoch 1402/2000\n",
      "606/606 [==============================] - 0s 46us/step - loss: 4.6780\n",
      "Epoch 1403/2000\n",
      "606/606 [==============================] - 0s 51us/step - loss: 4.6772\n",
      "Epoch 1404/2000\n",
      "606/606 [==============================] - 0s 49us/step - loss: 4.6764\n",
      "Epoch 1405/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.6756\n",
      "Epoch 1406/2000\n",
      "606/606 [==============================] - 0s 45us/step - loss: 4.6748\n",
      "Epoch 1407/2000\n",
      "606/606 [==============================] - 0s 48us/step - loss: 4.6741\n",
      "Epoch 1408/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6733\n",
      "Epoch 1409/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6726\n",
      "Epoch 1410/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6719\n",
      "Epoch 1411/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6712\n",
      "Epoch 1412/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6705\n",
      "Epoch 1413/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6698\n",
      "Epoch 1414/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6691\n",
      "Epoch 1415/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6685\n",
      "Epoch 1416/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6678\n",
      "Epoch 1417/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6672\n",
      "Epoch 1418/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6666\n",
      "Epoch 1419/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6660\n",
      "Epoch 1420/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6654\n",
      "Epoch 1421/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6649\n",
      "Epoch 1422/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.6643\n",
      "Epoch 1423/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6638\n",
      "Epoch 1424/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6633\n",
      "Epoch 1425/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1426/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6623\n",
      "Epoch 1427/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.6618\n",
      "Epoch 1428/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6613\n",
      "Epoch 1429/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.6609\n",
      "Epoch 1430/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6604\n",
      "Epoch 1431/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.6600\n",
      "Epoch 1432/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.6596\n",
      "Epoch 1433/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.6591\n",
      "Epoch 1434/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6587\n",
      "Epoch 1435/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6583\n",
      "Epoch 1436/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6579\n",
      "Epoch 1437/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6575\n",
      "Epoch 1438/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.6572\n",
      "Epoch 1439/2000\n",
      "606/606 [==============================] - 0s 46us/step - loss: 4.6568\n",
      "Epoch 1440/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 4.6564\n",
      "Epoch 1441/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 4.6560\n",
      "Epoch 1442/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6557\n",
      "Epoch 1443/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6553\n",
      "Epoch 1444/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.6549\n",
      "Epoch 1445/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6546\n",
      "Epoch 1446/2000\n",
      "606/606 [==============================] - 0s 50us/step - loss: 4.6542\n",
      "Epoch 1447/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.6539\n",
      "Epoch 1448/2000\n",
      "606/606 [==============================] - 0s 47us/step - loss: 4.6535\n",
      "Epoch 1449/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6532\n",
      "Epoch 1450/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6528\n",
      "Epoch 1451/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6525\n",
      "Epoch 1452/2000\n",
      "606/606 [==============================] - 0s 45us/step - loss: 4.6522\n",
      "Epoch 1453/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6518\n",
      "Epoch 1454/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6515\n",
      "Epoch 1455/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6512\n",
      "Epoch 1456/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6508\n",
      "Epoch 1457/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6505\n",
      "Epoch 1458/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 4.6502\n",
      "Epoch 1459/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6499\n",
      "Epoch 1460/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6495\n",
      "Epoch 1461/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6492\n",
      "Epoch 1462/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6489\n",
      "Epoch 1463/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6486\n",
      "Epoch 1464/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6483\n",
      "Epoch 1465/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6480\n",
      "Epoch 1466/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6477\n",
      "Epoch 1467/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6474\n",
      "Epoch 1468/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6471\n",
      "Epoch 1469/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6468\n",
      "Epoch 1470/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6465\n",
      "Epoch 1471/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6462\n",
      "Epoch 1472/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6459\n",
      "Epoch 1473/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6456\n",
      "Epoch 1474/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6453\n",
      "Epoch 1475/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6450\n",
      "Epoch 1476/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6447\n",
      "Epoch 1477/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6444\n",
      "Epoch 1478/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.6442\n",
      "Epoch 1479/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6439\n",
      "Epoch 1480/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6436\n",
      "Epoch 1481/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6433\n",
      "Epoch 1482/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6430\n",
      "Epoch 1483/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6428\n",
      "Epoch 1484/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6425\n",
      "Epoch 1485/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6422\n",
      "Epoch 1486/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6419\n",
      "Epoch 1487/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6417\n",
      "Epoch 1488/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6414\n",
      "Epoch 1489/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6411\n",
      "Epoch 1490/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6408\n",
      "Epoch 1491/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6406\n",
      "Epoch 1492/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6403\n",
      "Epoch 1493/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6401\n",
      "Epoch 1494/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6398\n",
      "Epoch 1495/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6395\n",
      "Epoch 1496/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6393\n",
      "Epoch 1497/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6390\n",
      "Epoch 1498/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6388\n",
      "Epoch 1499/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6385\n",
      "Epoch 1500/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6382\n",
      "Epoch 1501/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6380\n",
      "Epoch 1502/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6377\n",
      "Epoch 1503/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6375\n",
      "Epoch 1504/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6372\n",
      "Epoch 1505/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6370\n",
      "Epoch 1506/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6367\n",
      "Epoch 1507/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6365\n",
      "Epoch 1508/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6362\n",
      "Epoch 1509/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6360\n",
      "Epoch 1510/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.6357\n",
      "Epoch 1511/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6355\n",
      "Epoch 1512/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6353\n",
      "Epoch 1513/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6350\n",
      "Epoch 1514/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6348\n",
      "Epoch 1515/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6345\n",
      "Epoch 1516/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6343\n",
      "Epoch 1517/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6341\n",
      "Epoch 1518/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6338\n",
      "Epoch 1519/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6336\n",
      "Epoch 1520/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606/606 [==============================] - 0s 40us/step - loss: 4.6334\n",
      "Epoch 1521/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6331\n",
      "Epoch 1522/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6329\n",
      "Epoch 1523/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6326\n",
      "Epoch 1524/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6324\n",
      "Epoch 1525/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6322\n",
      "Epoch 1526/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.6320\n",
      "Epoch 1527/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6317\n",
      "Epoch 1528/2000\n",
      "606/606 [==============================] - 0s 47us/step - loss: 4.6315\n",
      "Epoch 1529/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.6313\n",
      "Epoch 1530/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6310\n",
      "Epoch 1531/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6308\n",
      "Epoch 1532/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6306\n",
      "Epoch 1533/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6304\n",
      "Epoch 1534/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 4.6301\n",
      "Epoch 1535/2000\n",
      "606/606 [==============================] - 0s 46us/step - loss: 4.6299\n",
      "Epoch 1536/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6297\n",
      "Epoch 1537/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6295\n",
      "Epoch 1538/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6292\n",
      "Epoch 1539/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6290\n",
      "Epoch 1540/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6288\n",
      "Epoch 1541/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6286\n",
      "Epoch 1542/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6284\n",
      "Epoch 1543/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6281\n",
      "Epoch 1544/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6279\n",
      "Epoch 1545/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6277\n",
      "Epoch 1546/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6275\n",
      "Epoch 1547/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6273\n",
      "Epoch 1548/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6270\n",
      "Epoch 1549/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6268\n",
      "Epoch 1550/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6266\n",
      "Epoch 1551/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6264\n",
      "Epoch 1552/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6262\n",
      "Epoch 1553/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6260\n",
      "Epoch 1554/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6258\n",
      "Epoch 1555/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6256\n",
      "Epoch 1556/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 4.6253\n",
      "Epoch 1557/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6251\n",
      "Epoch 1558/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6249\n",
      "Epoch 1559/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6247\n",
      "Epoch 1560/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6245\n",
      "Epoch 1561/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6243\n",
      "Epoch 1562/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6241\n",
      "Epoch 1563/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6239\n",
      "Epoch 1564/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6237\n",
      "Epoch 1565/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6235\n",
      "Epoch 1566/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6233\n",
      "Epoch 1567/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6231\n",
      "Epoch 1568/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6229\n",
      "Epoch 1569/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6227\n",
      "Epoch 1570/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6225\n",
      "Epoch 1571/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6223\n",
      "Epoch 1572/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6220\n",
      "Epoch 1573/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6218\n",
      "Epoch 1574/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6216\n",
      "Epoch 1575/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6214\n",
      "Epoch 1576/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6212\n",
      "Epoch 1577/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 4.6210\n",
      "Epoch 1578/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6208\n",
      "Epoch 1579/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6206\n",
      "Epoch 1580/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6205\n",
      "Epoch 1581/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6202\n",
      "Epoch 1582/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6201\n",
      "Epoch 1583/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6199\n",
      "Epoch 1584/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6197\n",
      "Epoch 1585/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.6195\n",
      "Epoch 1586/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6193\n",
      "Epoch 1587/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6191\n",
      "Epoch 1588/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6189\n",
      "Epoch 1589/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6187\n",
      "Epoch 1590/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6185\n",
      "Epoch 1591/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6183\n",
      "Epoch 1592/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6181\n",
      "Epoch 1593/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6179\n",
      "Epoch 1594/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6177\n",
      "Epoch 1595/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6175\n",
      "Epoch 1596/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6173\n",
      "Epoch 1597/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.6171\n",
      "Epoch 1598/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6169\n",
      "Epoch 1599/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6168\n",
      "Epoch 1600/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6166\n",
      "Epoch 1601/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6164\n",
      "Epoch 1602/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6162\n",
      "Epoch 1603/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6160\n",
      "Epoch 1604/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6158\n",
      "Epoch 1605/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6156\n",
      "Epoch 1606/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6154\n",
      "Epoch 1607/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6152\n",
      "Epoch 1608/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6151\n",
      "Epoch 1609/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.6149\n",
      "Epoch 1610/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6147\n",
      "Epoch 1611/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6145\n",
      "Epoch 1612/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6143\n",
      "Epoch 1613/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6141\n",
      "Epoch 1614/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1615/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6137\n",
      "Epoch 1616/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.6136\n",
      "Epoch 1617/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6134\n",
      "Epoch 1618/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6132\n",
      "Epoch 1619/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6130\n",
      "Epoch 1620/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6128\n",
      "Epoch 1621/2000\n",
      "606/606 [==============================] - 0s 46us/step - loss: 4.6127\n",
      "Epoch 1622/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.6125\n",
      "Epoch 1623/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6123\n",
      "Epoch 1624/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6121\n",
      "Epoch 1625/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6119\n",
      "Epoch 1626/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6117\n",
      "Epoch 1627/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6116\n",
      "Epoch 1628/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.6114\n",
      "Epoch 1629/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6112\n",
      "Epoch 1630/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6110\n",
      "Epoch 1631/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6108\n",
      "Epoch 1632/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6107\n",
      "Epoch 1633/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6105\n",
      "Epoch 1634/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6103\n",
      "Epoch 1635/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6101\n",
      "Epoch 1636/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6100\n",
      "Epoch 1637/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6098\n",
      "Epoch 1638/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6096\n",
      "Epoch 1639/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6094\n",
      "Epoch 1640/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6092\n",
      "Epoch 1641/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6091\n",
      "Epoch 1642/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6089\n",
      "Epoch 1643/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6087\n",
      "Epoch 1644/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6085\n",
      "Epoch 1645/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6084\n",
      "Epoch 1646/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6082\n",
      "Epoch 1647/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6080\n",
      "Epoch 1648/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6078\n",
      "Epoch 1649/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6077\n",
      "Epoch 1650/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6075\n",
      "Epoch 1651/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6073\n",
      "Epoch 1652/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6071\n",
      "Epoch 1653/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6070\n",
      "Epoch 1654/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6068\n",
      "Epoch 1655/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6066\n",
      "Epoch 1656/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6064\n",
      "Epoch 1657/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6063\n",
      "Epoch 1658/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6061\n",
      "Epoch 1659/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.6059\n",
      "Epoch 1660/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6058\n",
      "Epoch 1661/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6056\n",
      "Epoch 1662/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6054\n",
      "Epoch 1663/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6052\n",
      "Epoch 1664/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6051\n",
      "Epoch 1665/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6049\n",
      "Epoch 1666/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6047\n",
      "Epoch 1667/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6046\n",
      "Epoch 1668/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6044\n",
      "Epoch 1669/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6042\n",
      "Epoch 1670/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6041\n",
      "Epoch 1671/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.6039\n",
      "Epoch 1672/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6037\n",
      "Epoch 1673/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.6035\n",
      "Epoch 1674/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6034\n",
      "Epoch 1675/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6032\n",
      "Epoch 1676/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.6030\n",
      "Epoch 1677/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6029\n",
      "Epoch 1678/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.6027\n",
      "Epoch 1679/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6025\n",
      "Epoch 1680/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6024\n",
      "Epoch 1681/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6022\n",
      "Epoch 1682/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6020\n",
      "Epoch 1683/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6019\n",
      "Epoch 1684/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6017\n",
      "Epoch 1685/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.6015\n",
      "Epoch 1686/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6014\n",
      "Epoch 1687/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.6012\n",
      "Epoch 1688/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.6010\n",
      "Epoch 1689/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6009\n",
      "Epoch 1690/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.6007\n",
      "Epoch 1691/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.6006\n",
      "Epoch 1692/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6004\n",
      "Epoch 1693/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6002\n",
      "Epoch 1694/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6001\n",
      "Epoch 1695/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.5999\n",
      "Epoch 1696/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5997\n",
      "Epoch 1697/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.5996\n",
      "Epoch 1698/2000\n",
      "606/606 [==============================] - 0s 45us/step - loss: 4.5994\n",
      "Epoch 1699/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5992\n",
      "Epoch 1700/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.5991\n",
      "Epoch 1701/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5989\n",
      "Epoch 1702/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.5988\n",
      "Epoch 1703/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5986\n",
      "Epoch 1704/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.5984\n",
      "Epoch 1705/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5983\n",
      "Epoch 1706/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.5981\n",
      "Epoch 1707/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5979\n",
      "Epoch 1708/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5978\n",
      "Epoch 1709/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606/606 [==============================] - 0s 37us/step - loss: 4.5976\n",
      "Epoch 1710/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5975\n",
      "Epoch 1711/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.5973\n",
      "Epoch 1712/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.5971\n",
      "Epoch 1713/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.5970\n",
      "Epoch 1714/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.5968\n",
      "Epoch 1715/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.5967\n",
      "Epoch 1716/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.5965\n",
      "Epoch 1717/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5963\n",
      "Epoch 1718/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.5962\n",
      "Epoch 1719/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.5960\n",
      "Epoch 1720/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5959\n",
      "Epoch 1721/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5957\n",
      "Epoch 1722/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5955\n",
      "Epoch 1723/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5954\n",
      "Epoch 1724/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.5952\n",
      "Epoch 1725/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5951\n",
      "Epoch 1726/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5949\n",
      "Epoch 1727/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5948\n",
      "Epoch 1728/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.5946\n",
      "Epoch 1729/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5944\n",
      "Epoch 1730/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.5943\n",
      "Epoch 1731/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5941\n",
      "Epoch 1732/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5940\n",
      "Epoch 1733/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.5938\n",
      "Epoch 1734/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5937\n",
      "Epoch 1735/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.5935\n",
      "Epoch 1736/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.5933\n",
      "Epoch 1737/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.5932\n",
      "Epoch 1738/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.5930\n",
      "Epoch 1739/2000\n",
      "606/606 [==============================] - 0s 45us/step - loss: 4.5929\n",
      "Epoch 1740/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.5927\n",
      "Epoch 1741/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5926\n",
      "Epoch 1742/2000\n",
      "606/606 [==============================] - 0s 45us/step - loss: 4.5924\n",
      "Epoch 1743/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5923\n",
      "Epoch 1744/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.5921\n",
      "Epoch 1745/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 4.5919\n",
      "Epoch 1746/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5918\n",
      "Epoch 1747/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5916\n",
      "Epoch 1748/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5915\n",
      "Epoch 1749/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.5913\n",
      "Epoch 1750/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5912\n",
      "Epoch 1751/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5910\n",
      "Epoch 1752/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.5909\n",
      "Epoch 1753/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.5907\n",
      "Epoch 1754/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.5905\n",
      "Epoch 1755/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5904\n",
      "Epoch 1756/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5902\n",
      "Epoch 1757/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5901\n",
      "Epoch 1758/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5899\n",
      "Epoch 1759/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5898\n",
      "Epoch 1760/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5896\n",
      "Epoch 1761/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5895\n",
      "Epoch 1762/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5893\n",
      "Epoch 1763/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.5892\n",
      "Epoch 1764/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5890\n",
      "Epoch 1765/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5889\n",
      "Epoch 1766/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5887\n",
      "Epoch 1767/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.5886\n",
      "Epoch 1768/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5884\n",
      "Epoch 1769/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5883\n",
      "Epoch 1770/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.5881\n",
      "Epoch 1771/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5880\n",
      "Epoch 1772/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5878\n",
      "Epoch 1773/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5877\n",
      "Epoch 1774/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5875\n",
      "Epoch 1775/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5874\n",
      "Epoch 1776/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.5872\n",
      "Epoch 1777/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5871\n",
      "Epoch 1778/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5869\n",
      "Epoch 1779/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5868\n",
      "Epoch 1780/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5866\n",
      "Epoch 1781/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.5865\n",
      "Epoch 1782/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.5863\n",
      "Epoch 1783/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.5862\n",
      "Epoch 1784/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5860\n",
      "Epoch 1785/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5859\n",
      "Epoch 1786/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5857\n",
      "Epoch 1787/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5856\n",
      "Epoch 1788/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.5854\n",
      "Epoch 1789/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.5853\n",
      "Epoch 1790/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.5851\n",
      "Epoch 1791/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5850\n",
      "Epoch 1792/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.5848\n",
      "Epoch 1793/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5847\n",
      "Epoch 1794/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.5845\n",
      "Epoch 1795/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5844\n",
      "Epoch 1796/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5842\n",
      "Epoch 1797/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5841\n",
      "Epoch 1798/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5839\n",
      "Epoch 1799/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.5838\n",
      "Epoch 1800/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 4.5836\n",
      "Epoch 1801/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5835\n",
      "Epoch 1802/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5834\n",
      "Epoch 1803/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1804/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.5831\n",
      "Epoch 1805/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.5829\n",
      "Epoch 1806/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.5828\n",
      "Epoch 1807/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5826\n",
      "Epoch 1808/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 4.5825\n",
      "Epoch 1809/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5823\n",
      "Epoch 1810/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.5822\n",
      "Epoch 1811/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.5820\n",
      "Epoch 1812/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.5819\n",
      "Epoch 1813/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.5818\n",
      "Epoch 1814/2000\n",
      "606/606 [==============================] - 0s 46us/step - loss: 4.5816\n",
      "Epoch 1815/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5815\n",
      "Epoch 1816/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.5813\n",
      "Epoch 1817/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5812\n",
      "Epoch 1818/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.5810\n",
      "Epoch 1819/2000\n",
      "606/606 [==============================] - 0s 47us/step - loss: 4.5809\n",
      "Epoch 1820/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.5807\n",
      "Epoch 1821/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5806\n",
      "Epoch 1822/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.5804\n",
      "Epoch 1823/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5803\n",
      "Epoch 1824/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5802\n",
      "Epoch 1825/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.5800\n",
      "Epoch 1826/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.5799\n",
      "Epoch 1827/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 4.5797\n",
      "Epoch 1828/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.5796\n",
      "Epoch 1829/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.5794\n",
      "Epoch 1830/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.5793\n",
      "Epoch 1831/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.5792\n",
      "Epoch 1832/2000\n",
      "606/606 [==============================] - 0s 77us/step - loss: 4.5790\n",
      "Epoch 1833/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5789\n",
      "Epoch 1834/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.5787\n",
      "Epoch 1835/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5786\n",
      "Epoch 1836/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5784\n",
      "Epoch 1837/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.5783\n",
      "Epoch 1838/2000\n",
      "606/606 [==============================] - 0s 52us/step - loss: 4.5782\n",
      "Epoch 1839/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5780\n",
      "Epoch 1840/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5779\n",
      "Epoch 1841/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5777\n",
      "Epoch 1842/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.5776\n",
      "Epoch 1843/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.5774\n",
      "Epoch 1844/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.5773\n",
      "Epoch 1845/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5772\n",
      "Epoch 1846/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.5770\n",
      "Epoch 1847/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5769\n",
      "Epoch 1848/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5767\n",
      "Epoch 1849/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.5766\n",
      "Epoch 1850/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.5764\n",
      "Epoch 1851/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5763\n",
      "Epoch 1852/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5762\n",
      "Epoch 1853/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.5760\n",
      "Epoch 1854/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5759\n",
      "Epoch 1855/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.5757\n",
      "Epoch 1856/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5756\n",
      "Epoch 1857/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5755\n",
      "Epoch 1858/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5753\n",
      "Epoch 1859/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5752\n",
      "Epoch 1860/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.5750\n",
      "Epoch 1861/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5749\n",
      "Epoch 1862/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.5748\n",
      "Epoch 1863/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5746\n",
      "Epoch 1864/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5745\n",
      "Epoch 1865/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5743\n",
      "Epoch 1866/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.5742\n",
      "Epoch 1867/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5741\n",
      "Epoch 1868/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5739\n",
      "Epoch 1869/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.5738\n",
      "Epoch 1870/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.5736\n",
      "Epoch 1871/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5735\n",
      "Epoch 1872/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.5734\n",
      "Epoch 1873/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.5732\n",
      "Epoch 1874/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5731\n",
      "Epoch 1875/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.5729\n",
      "Epoch 1876/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5728\n",
      "Epoch 1877/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5727\n",
      "Epoch 1878/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5725\n",
      "Epoch 1879/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5724\n",
      "Epoch 1880/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5723\n",
      "Epoch 1881/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.5721\n",
      "Epoch 1882/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.5720\n",
      "Epoch 1883/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5718\n",
      "Epoch 1884/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5717\n",
      "Epoch 1885/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5716\n",
      "Epoch 1886/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.5714\n",
      "Epoch 1887/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.5713\n",
      "Epoch 1888/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.5711\n",
      "Epoch 1889/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5710\n",
      "Epoch 1890/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.5709\n",
      "Epoch 1891/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5707\n",
      "Epoch 1892/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5706\n",
      "Epoch 1893/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5705\n",
      "Epoch 1894/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5703\n",
      "Epoch 1895/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.5702\n",
      "Epoch 1896/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.5700\n",
      "Epoch 1897/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5699\n",
      "Epoch 1898/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606/606 [==============================] - 0s 36us/step - loss: 4.5698\n",
      "Epoch 1899/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5696\n",
      "Epoch 1900/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5695\n",
      "Epoch 1901/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.5694\n",
      "Epoch 1902/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.5692\n",
      "Epoch 1903/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.5691\n",
      "Epoch 1904/2000\n",
      "606/606 [==============================] - 0s 45us/step - loss: 4.5690\n",
      "Epoch 1905/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.5688\n",
      "Epoch 1906/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.5687\n",
      "Epoch 1907/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.5685\n",
      "Epoch 1908/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.5684\n",
      "Epoch 1909/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5683\n",
      "Epoch 1910/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.5681\n",
      "Epoch 1911/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5680\n",
      "Epoch 1912/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.5679\n",
      "Epoch 1913/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.5677\n",
      "Epoch 1914/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.5676\n",
      "Epoch 1915/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.5675\n",
      "Epoch 1916/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.5673\n",
      "Epoch 1917/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5672\n",
      "Epoch 1918/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.5670\n",
      "Epoch 1919/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.5669\n",
      "Epoch 1920/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.5668\n",
      "Epoch 1921/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.5666\n",
      "Epoch 1922/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.5665\n",
      "Epoch 1923/2000\n",
      "606/606 [==============================] - 0s 47us/step - loss: 4.5664\n",
      "Epoch 1924/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.5662\n",
      "Epoch 1925/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.5661\n",
      "Epoch 1926/2000\n",
      "606/606 [==============================] - 0s 51us/step - loss: 4.5660\n",
      "Epoch 1927/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.5658\n",
      "Epoch 1928/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.5657\n",
      "Epoch 1929/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5656\n",
      "Epoch 1930/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.5654\n",
      "Epoch 1931/2000\n",
      "606/606 [==============================] - 0s 48us/step - loss: 4.5653\n",
      "Epoch 1932/2000\n",
      "606/606 [==============================] - 0s 46us/step - loss: 4.5652\n",
      "Epoch 1933/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5650\n",
      "Epoch 1934/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.5649\n",
      "Epoch 1935/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.5648\n",
      "Epoch 1936/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5646\n",
      "Epoch 1937/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5645\n",
      "Epoch 1938/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.5644\n",
      "Epoch 1939/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5642\n",
      "Epoch 1940/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 4.5641\n",
      "Epoch 1941/2000\n",
      "606/606 [==============================] - 0s 43us/step - loss: 4.5640\n",
      "Epoch 1942/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5638\n",
      "Epoch 1943/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5637\n",
      "Epoch 1944/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5636\n",
      "Epoch 1945/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5634\n",
      "Epoch 1946/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.5633\n",
      "Epoch 1947/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5632\n",
      "Epoch 1948/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5630\n",
      "Epoch 1949/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.5629\n",
      "Epoch 1950/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5628\n",
      "Epoch 1951/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.5626\n",
      "Epoch 1952/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5625\n",
      "Epoch 1953/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5624\n",
      "Epoch 1954/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5622\n",
      "Epoch 1955/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.5621\n",
      "Epoch 1956/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5620\n",
      "Epoch 1957/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.5619\n",
      "Epoch 1958/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5618\n",
      "Epoch 1959/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.5617\n",
      "Epoch 1960/2000\n",
      "606/606 [==============================] - 0s 39us/step - loss: 4.5617\n",
      "Epoch 1961/2000\n",
      "606/606 [==============================] - 0s 45us/step - loss: 4.5619\n",
      "Epoch 1962/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.5627\n",
      "Epoch 1963/2000\n",
      "606/606 [==============================] - 0s 41us/step - loss: 4.5640\n",
      "Epoch 1964/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5686\n",
      "Epoch 1965/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.5720\n",
      "Epoch 1966/2000\n",
      "606/606 [==============================] - 0s 34us/step - loss: 4.5918\n",
      "Epoch 1967/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5806\n",
      "Epoch 1968/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.5966\n",
      "Epoch 1969/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.5716\n",
      "Epoch 1970/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5649\n",
      "Epoch 1971/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.5609\n",
      "Epoch 1972/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5609\n",
      "Epoch 1973/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5645\n",
      "Epoch 1974/2000\n",
      "606/606 [==============================] - 0s 33us/step - loss: 4.5706\n",
      "Epoch 1975/2000\n",
      "606/606 [==============================] - 0s 31us/step - loss: 4.5974\n",
      "Epoch 1976/2000\n",
      "606/606 [==============================] - 0s 38us/step - loss: 4.5899\n",
      "Epoch 1977/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6403\n",
      "Epoch 1978/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5688\n",
      "Epoch 1979/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5648\n",
      "Epoch 1980/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.6003\n",
      "Epoch 1981/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5843\n",
      "Epoch 1982/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5914\n",
      "Epoch 1983/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.5646\n",
      "Epoch 1984/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5591\n",
      "Epoch 1985/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5666\n",
      "Epoch 1986/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5822\n",
      "Epoch 1987/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.6578\n",
      "Epoch 1988/2000\n",
      "606/606 [==============================] - 0s 32us/step - loss: 4.5754\n",
      "Epoch 1989/2000\n",
      "606/606 [==============================] - 0s 44us/step - loss: 4.5594\n",
      "Epoch 1990/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.5606\n",
      "Epoch 1991/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5720\n",
      "Epoch 1992/2000\n",
      "606/606 [==============================] - 0s 35us/step - loss: 4.6061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1993/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5743\n",
      "Epoch 1994/2000\n",
      "606/606 [==============================] - 0s 36us/step - loss: 4.5673\n",
      "Epoch 1995/2000\n",
      "606/606 [==============================] - 0s 40us/step - loss: 4.5595\n",
      "Epoch 1996/2000\n",
      "606/606 [==============================] - 0s 46us/step - loss: 4.5573\n",
      "Epoch 1997/2000\n",
      "606/606 [==============================] - 0s 47us/step - loss: 4.5576\n",
      "Epoch 1998/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.5605\n",
      "Epoch 1999/2000\n",
      "606/606 [==============================] - 0s 42us/step - loss: 4.5713\n",
      "Epoch 2000/2000\n",
      "606/606 [==============================] - 0s 37us/step - loss: 4.5853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x139cd8ac8>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmbda = 0.\n",
    "alpha = 1.\n",
    "\n",
    "l1_weight = lmbda * alpha\n",
    "l2_weight = lmbda * (1-alpha) / 2.\n",
    "\n",
    "coxph_neural = models.Sequential()\n",
    "coxph_neural.add(layers.Dense(32, activation=None, input_shape=(x.shape[1],), \n",
    "                              use_bias=False))\n",
    "coxph_neural.add(layers.Dense(1, activation=None, input_shape=(32,),\n",
    "                              kernel_regularizer=regularizers.L1L2(l1_weight,\n",
    "                                                                   l2_weight),\n",
    "                              use_bias=False))\n",
    "coxph_neural.add(layers.Lambda(lambda x: K.concatenate([x, K.ones_like(x)],\n",
    "                                                       axis=-1)))\n",
    "coxph_neural.summary()\n",
    "\n",
    "coxph_neural.compile(optimizer='Adam', loss=coxph_partial_log_likelihood)\n",
    "\n",
    "coxph_neural.fit(x_standardized, y, epochs=2000, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.28023645 -0.24846472  0.11507466  0.27994847  0.12641987 -0.0598039\n",
      " -0.21215709  0.06491791  0.40387827 -0.14368719  0.0428552   0.24639003\n",
      "  0.20154762  0.26910502 -0.15866931  0.34842864  0.32280126 -0.27129138\n",
      " -0.38234323  0.16286236  0.30582955  0.06486453  0.02401401  0.04277959\n",
      " -0.22527002  0.42446542 -0.21362258  0.30726275  0.09832785  0.18886165\n",
      " -0.0597869  -0.39095786]\n"
     ]
    }
   ],
   "source": [
    "# just as with Lifelines' Cox proportional hazards model fitter, we undo the\n",
    "# standard deviation scaling here (but not the mean removal)\n",
    "weights = coxph_neural.get_weights()[1].flatten()\n",
    "print(weights)\n",
    "# coxph_neural_beta = weights[0].flatten() / standard_scaler.scale_\n",
    "# print('Beta:', coxph_neural_beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0.]), array([0., 0.])]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ndarray((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-6bdcfe467973>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "a[0][0] = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
