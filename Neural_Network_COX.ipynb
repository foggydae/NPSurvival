{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras code for Cox proportional hazards survival layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Survival.Utils import load_whole_data\n",
    "from Survival.Utils import load_val_data\n",
    "from Survival.Utils import calc_scores\n",
    "from Survival.Utils import load_score_containers\n",
    "from Survival.Utils import filename_generator\n",
    "\n",
    "from Survival.NeuralNetworkCox import NeuralNetworkCox\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full dataset performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current dataset: pancreatitis\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 7 times.\n",
      "[LOG]Number of events that ever occurred: 1566\n",
      "[LOG]Number of events that occurred for more than 7 times: 592\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 3 times.\n",
      "[LOG]After one-hot encoding, number of feature: 955\n",
      "[LOG]Among them, number of categorical feature: 616\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/fancyimpute/soft_impute.py:100: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return (np.sqrt(ssd) / old_norm) < self.convergence_threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current dataset: ich\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 10 times.\n",
      "[LOG]Number of events that ever occurred: 1966\n",
      "[LOG]Number of events that occurred for more than 10 times: 789\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 5 times.\n",
      "[LOG]After one-hot encoding, number of feature: 1512\n",
      "[LOG]Among them, number of categorical feature: 1093\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "current dataset: sepsis\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 37 times.\n",
      "[LOG]Number of events that ever occurred: 4373\n",
      "[LOG]Number of events that occurred for more than 37 times: 1167\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 12 times.\n",
      "[LOG]After one-hot encoding, number of feature: 1834\n",
      "[LOG]Among them, number of categorical feature: 1019\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n"
     ]
    }
   ],
   "source": [
    "dataset_idxs = [2] # 0: \"pancreatitis\", 1: \"ich\", 2: \"sepsis\"\n",
    "train_dfs, test_dfs, unique_times, dataset_names = \\\n",
    "    load_whole_data(dataset_idxs, verbose=True, data_path=\"../../dataset/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try on the complete **Pancreatitis** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_dfs[dataset_names[0]]\n",
    "test_df = test_dfs[dataset_names[0]]\n",
    "unique_time = unique_times[dataset_names[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.4 s, sys: 1.16 s, total: 13.6 s\n",
      "Wall time: 8.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NNCOX = NeuralNetworkCox(first_layer_size=16, epochs=1500, verbose=0)\n",
    "NNCOX.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48542761586239846 4.109481129197608\n",
      "CPU times: user 1.05 s, sys: 11.3 ms, total: 1.06 s\n",
      "Wall time: 1.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "PAN_concordance, PAN_IPEC_list = calc_scores(NNCOX, test_df, unique_time)\n",
    "print(PAN_concordance, PAN_IPEC_list[int(len(PAN_IPEC_list) * 0.8)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try on the complete **Ich** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_dfs[dataset_names[1]]\n",
    "test_df = test_dfs[dataset_names[1]]\n",
    "unique_time = unique_times[dataset_names[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.7 s, sys: 3.89 s, total: 52.5 s\n",
      "Wall time: 33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NNCOX = NeuralNetworkCox(first_layer_size=16, epochs=1500, verbose=0)\n",
    "NNCOX.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5738948966040599 1.6895809967736664\n",
      "CPU times: user 8.55 s, sys: 57.4 ms, total: 8.61 s\n",
      "Wall time: 8.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ICH_concordance, ICH_IPEC_list = calc_scores(NNCOX, test_df, unique_time)\n",
    "print(ICH_concordance, ICH_IPEC_list[int(len(ICH_IPEC_list) * 0.8)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try on the complete **Spesis** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_dfs[dataset_names[2]]\n",
    "test_df = test_dfs[dataset_names[2]]\n",
    "unique_time = unique_times[dataset_names[2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "NNCOX = NeuralNetworkCox(first_layer_size=16, epochs=1500, verbose=1)\n",
    "NNCOX.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "SEP_concordance, SEP_IPEC_list = calc_scores(NNCOX, test_df, unique_time)\n",
    "print(SEP_concordance, SEP_IPEC_list[int(len(SEP_IPEC_list) * 0.8)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Scripts Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current dataset: ich\n",
      "---------------------------------------------\n",
      "fold 0\n",
      "1204 16:15:17\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 7 times.\n",
      "[LOG]Number of events that ever occurred: 1896\n",
      "[LOG]Number of events that occurred for more than 7 times: 817\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 3 times.\n",
      "[LOG]After one-hot encoding, number of feature: 1709\n",
      "[LOG]Among them, number of categorical feature: 1277\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/fancyimpute/soft_impute.py:100: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return (np.sqrt(ssd) / old_norm) < self.convergence_threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "fold 1\n",
      "1204 16:17:54\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 7 times.\n",
      "[LOG]Number of events that ever occurred: 1896\n",
      "[LOG]Number of events that occurred for more than 7 times: 817\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 3 times.\n",
      "[LOG]After one-hot encoding, number of feature: 1709\n",
      "[LOG]Among them, number of categorical feature: 1277\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 2\n",
      "1204 16:20:30\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 7 times.\n",
      "[LOG]Number of events that ever occurred: 1896\n",
      "[LOG]Number of events that occurred for more than 7 times: 817\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 3 times.\n",
      "[LOG]After one-hot encoding, number of feature: 1709\n",
      "[LOG]Among them, number of categorical feature: 1277\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 3\n",
      "1204 16:23:24\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 7 times.\n",
      "[LOG]Number of events that ever occurred: 1896\n",
      "[LOG]Number of events that occurred for more than 7 times: 817\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 3 times.\n",
      "[LOG]After one-hot encoding, number of feature: 1709\n",
      "[LOG]Among them, number of categorical feature: 1277\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n",
      "---------------------------------------------\n",
      "fold 4\n",
      "1204 16:25:53\n",
      "[LOG]Reading train&test csv...\n",
      "[LOG]Process df row by row and update dict.\n",
      "[LOG]Reading patient list, LoS, TUD...\n",
      "[LOG]Identify one-hot encoded event, extract 'true event' and value.\n",
      "[LOG]Count occurance for each event; Remove 'na' in value.\n",
      "[LOG]Feature filtering. Remove events that occurred for less than 7 times.\n",
      "[LOG]Number of events that ever occurred: 1896\n",
      "[LOG]Number of events that occurred for more than 7 times: 817\n",
      "[LOG]Identify categorical event.\n",
      "[LOG]One-hot encoding categorical event. Scalarize numerical.\n",
      "[LOG]Value filtering. Remove values that occurred for less than 3 times.\n",
      "[LOG]After one-hot encoding, number of feature: 1709\n",
      "[LOG]Among them, number of categorical feature: 1277\n",
      "[LOG]Simplify output dict and check correctness.\n",
      "[LOG]Impute missing value.\n"
     ]
    }
   ],
   "source": [
    "dataset_idxs = [1]  # 0: \"pancreatitis\", 1: \"ich\", 2: \"sepsis\"\n",
    "train_dfs, test_dfs, unique_times, dataset_names = load_val_data(dataset_idxs, True, \"../../dataset/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For the ich dataset:\n",
      "[LOG] first_layer = 8, lmbda = 0.0\n",
      "0 0.536467410247473 2.5726878434244096\n",
      "1 0.5771174625304984 1.946086385858014\n",
      "2 0.5572063436737539 2.253182068934815\n",
      "3 0.606887417218543 1.9157242022043144\n",
      "4 0.5618543046357616 1.9405950389646305\n",
      "[LOG] avg. concordance: 0.5679065876612059\n",
      "[LOG] avg. ipec: 2.125655107877237\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 8, lmbda = 0.01\n",
      "0 0.5263593586615546 2.49153391056251\n",
      "1 0.5650052283025444 1.9970687760911325\n",
      "2 0.5837835482746602 1.9975147641776614\n",
      "3 0.4781456953642384 3.523432923985743\n",
      "4 0.5756291390728476 1.8836456279395584\n",
      "[LOG] avg. concordance: 0.5457845939351691\n",
      "[LOG] avg. ipec: 2.378639200551321\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 8, lmbda = 0.02\n",
      "0 0.5271436040432206 2.620830701179726\n",
      "1 0.5731526664342976 1.9493256046082166\n",
      "2 0.5728912513070756 2.0966761007161074\n",
      "3 0.5835761589403974 1.909387731832924\n",
      "4 0.5408830022075055 2.055451793653473\n",
      "[LOG] avg. concordance: 0.5595293365864993\n",
      "[LOG] avg. ipec: 2.1263343863980895\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 8, lmbda = 0.06\n",
      "0 0.5331561519693273 2.454760806950071\n",
      "1 0.5823893342628094 1.8614099952827619\n",
      "2 0.5727169745555943 2.093154727406502\n",
      "3 0.5817218543046357 2.0060770094517895\n",
      "4 0.5775717439293598 1.9143591920789191\n",
      "[LOG] avg. concordance: 0.5695112118043453\n",
      "[LOG] avg. ipec: 2.065952346234009\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 8, lmbda = 0.1\n",
      "0 0.5438741721854304 2.2705473307095425\n",
      "1 0.6018647612408504 1.701645749396835\n",
      "2 0.5889247124433601 1.8204202521838078\n",
      "3 0.5863134657836645 1.771691934969422\n",
      "4 0.5898896247240618 1.7806071720794014\n",
      "[LOG] avg. concordance: 0.5821733472754734\n",
      "[LOG] avg. ipec: 1.8689824878678016\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 8, lmbda = 0.12\n",
      "0 0.5474468455907981 2.190006193557408\n",
      "1 0.6032154060648309 1.5992692028031317\n",
      "2 0.6001219937260369 1.7679316458573842\n",
      "3 0.5936423841059603 1.8593562823623302\n",
      "4 0.580309050772627 1.7824983562482921\n",
      "[LOG] avg. concordance: 0.5849471360520507\n",
      "[LOG] avg. ipec: 1.8398123361657093\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 8, lmbda = 0.15\n",
      "0 0.5593412338794005 2.0180387595561484\n",
      "1 0.610186476124085 1.543596825621865\n",
      "2 0.5970721505751133 1.8161976182949662\n",
      "3 0.6136423841059603 1.641395293240597\n",
      "4 0.5957615894039735 1.7425436891847517\n",
      "[LOG] avg. concordance: 0.5952007668177066\n",
      "[LOG] avg. ipec: 1.7523544371796658\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 16, lmbda = 0.0\n",
      "0 0.5261850819100732 2.5142079432652227\n",
      "1 0.5776402927849424 1.932718138430338\n",
      "2 0.5779888462879051 2.050025509997917\n",
      "3 0.582075055187638 1.9548071255767245\n",
      "4 0.5685209713024283 1.7940734468362387\n",
      "[LOG] avg. concordance: 0.5664820494945974\n",
      "[LOG] avg. ipec: 2.049166432821288\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 16, lmbda = 0.01\n",
      "0 0.5301063088184036 2.538873049078368\n",
      "1 0.5989891948414081 1.7804112507885825\n",
      "2 0.5708434994771697 1.9816118956715294\n",
      "3 0.5688300220750552 1.9808242780262075\n",
      "4 0.5750993377483443 1.9595166936400914\n",
      "[LOG] avg. concordance: 0.5687736725920762\n",
      "[LOG] avg. ipec: 2.0482474334409555\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 16, lmbda = 0.02\n",
      "0 0.5292784942488672 2.4806965230829983\n",
      "1 0.5855263157894737 1.9245602119040495\n",
      "2 0.5680115022655978 2.1799742955174866\n",
      "3 0.5841059602649007 2.065109572915904\n",
      "4 0.5730242825607064 1.8780361159547045\n",
      "[LOG] avg. concordance: 0.5679893110259091\n",
      "[LOG] avg. ipec: 2.1056753438750286\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 16, lmbda = 0.06\n",
      "0 0.5372516556291391 2.3816617779167704\n",
      "1 0.5865719762983618 1.7774926222171772\n",
      "2 0.5722812826768909 2.034158121845305\n",
      "3 0.5925386313465784 1.900989604528152\n",
      "4 0.5724503311258278 1.85435887086931\n",
      "[LOG] avg. concordance: 0.5722187754153596\n",
      "[LOG] avg. ipec: 1.989732199475343\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 16, lmbda = 0.1\n",
      "0 0.5359445799930289 2.2908186740916534\n",
      "1 0.6060909724642732 1.7021626369630614\n",
      "2 0.5977692575810387 1.8499165341701598\n",
      "3 0.5903311258278146 1.8024864977354842\n",
      "4 0.5877262693156733 1.7824654740129424\n",
      "[LOG] avg. concordance: 0.5835724410363657\n",
      "[LOG] avg. ipec: 1.8855699633946603\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 16, lmbda = 0.12\n",
      "0 0.5529365632624608 2.1351235598371234\n",
      "1 0.606700941094458 1.61455461855404\n",
      "2 0.5842628093412339 1.7939998355098443\n",
      "3 0.5925386313465784 1.6927272610495623\n",
      "4 0.5832671081677704 1.7748239407403585\n",
      "[LOG] avg. concordance: 0.5839412106425004\n",
      "[LOG] avg. ipec: 1.8022458431381856\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 16, lmbda = 0.15\n",
      "0 0.557598466364587 2.1014866847601783\n",
      "1 0.6128441965841757 1.5833962177483674\n",
      "2 0.5996863018473335 1.6733254331581175\n",
      "3 0.6049006622516556 1.6250900138832292\n",
      "4 0.5938631346578367 1.6513799143956247\n",
      "[LOG] avg. concordance: 0.5937785523411176\n",
      "[LOG] avg. ipec: 1.7269356527891033\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 32, lmbda = 0.0\n",
      "0 0.5125479261066573 2.6294132857585737\n",
      "1 0.5809079818752179 1.8509931226872332\n",
      "2 0.5704078075984663 2.063965589358357\n",
      "3 0.5714790286975717 2.0461029684090395\n",
      "4 0.5226931567328919 2.241419901702958\n",
      "[LOG] avg. concordance: 0.551607180202161\n",
      "[LOG] avg. ipec: 2.1663789735832326\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 32, lmbda = 0.01\n",
      "0 0.5156413384454513 2.5883103158922784\n",
      "1 0.5908853258975253 1.7529536947667457\n",
      "2 0.5799930289299408 1.956157065195261\n",
      "3 0.5971302428256071 1.84529698981871\n",
      "4 0.5954083885209713 1.7576216866688545\n",
      "[LOG] avg. concordance: 0.5758116649238991\n",
      "[LOG] avg. ipec: 1.98006795046837\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 32, lmbda = 0.02\n",
      "0 0.5305855698849773 2.32840295690179\n",
      "1 0.576420355524573 1.941507824390203\n",
      "2 0.5750261415127222 2.0347692997218374\n",
      "3 0.6167328918322296 1.688846583446156\n",
      "4 0.580794701986755 1.8398873581341546\n",
      "[LOG] avg. concordance: 0.5759119321482514\n",
      "[LOG] avg. ipec: 1.9666828045188283\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 32, lmbda = 0.06\n",
      "0 0.5287556639944232 2.440811002637911\n",
      "1 0.5884454513767864 1.7552961756370624\n",
      "2 0.5618246775880098 2.2235165154247607\n",
      "3 0.5826048565121413 1.8728838871127973\n",
      "4 0.5908167770419426 1.7620530062552493\n",
      "[LOG] avg. concordance: 0.5704894853026606\n",
      "[LOG] avg. ipec: 2.010912117413556\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 32, lmbda = 0.1\n",
      "0 0.5545486232136633 2.076317598918729\n",
      "1 0.6056117113976995 1.5925631531258713\n",
      "2 0.5972028581387243 1.7367668581492273\n",
      "3 0.6045916114790287 1.6641235286744187\n",
      "4 0.5977924944812362 1.7067415537099557\n",
      "[LOG] avg. concordance: 0.5919494597420705\n",
      "[LOG] avg. ipec: 1.7553025385156402\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 32, lmbda = 0.12\n",
      "0 0.561084001394214 2.0170976703122014\n",
      "1 0.5720198675496688 2.0210397901570922\n",
      "2 0.6029975601254792 1.6764289901330927\n",
      "3 0.6137748344370861 1.6011674030405492\n",
      "4 0.5871081677704194 1.671961213773804\n",
      "[LOG] avg. concordance: 0.5873968862553735\n",
      "[LOG] avg. ipec: 1.7975390134833478\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 32, lmbda = 0.15\n",
      "0 0.563785291042175 1.995107326447018\n",
      "1 0.6253049843150924 1.39966767568537\n",
      "2 0.6029539909376089 1.6115644842243377\n",
      "3 0.6027814569536424 1.6425845692780219\n",
      "4 0.5873730684326711 1.71657678632038\n",
      "[LOG] avg. concordance: 0.596439758336238\n",
      "[LOG] avg. ipec: 1.6731001683910254\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 64, lmbda = 0.0\n",
      "0 0.5445712791913558 1.9987800182858355\n",
      "1 0.5742854653189264 1.9216416730519885\n",
      "2 0.5890989891948414 1.9551952741408452\n",
      "3 0.5894481236203091 1.7563874622111253\n",
      "4 0.5731125827814569 1.9766664830392788\n",
      "[LOG] avg. concordance: 0.574103288021378\n",
      "[LOG] avg. ipec: 1.921734182145815\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 64, lmbda = 0.01\n",
      "0 0.5286685256186825 2.403853271817073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.5935866155454862 1.7302743035516008\n",
      "2 0.563785291042175 2.092565665143125\n",
      "3 0.5764238410596026 2.0208290512572513\n",
      "4 0.56158940397351 2.2704933528750884\n",
      "[LOG] avg. concordance: 0.5648107354478913\n",
      "[LOG] avg. ipec: 2.1036031289288273\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 64, lmbda = 0.02\n",
      "0 0.5388201463924712 2.3005170938971027\n",
      "1 0.576551063088184 1.9490390038484997\n",
      "2 0.5664865806901359 2.052731979196542\n",
      "3 0.5911699779249449 1.931053314004929\n",
      "4 0.5658719646799117 1.9808772435366124\n",
      "[LOG] avg. concordance: 0.5677799465551295\n",
      "[LOG] avg. ipec: 2.042843726896737\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 64, lmbda = 0.06\n",
      "0 0.5411293133495991 2.248101626774127\n",
      "1 0.6123213663297317 1.5923719127782932\n",
      "2 0.5891861275705821 1.858667105861098\n",
      "3 0.600485651214128 1.8174994677770135\n",
      "4 0.5831346578366446 1.831722066984918\n",
      "[LOG] avg. concordance: 0.5852514232601371\n",
      "[LOG] avg. ipec: 1.8696724360350898\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 64, lmbda = 0.1\n",
      "0 0.5562478215406065 2.116520522641199\n",
      "1 0.6017776228651098 1.5387358735711587\n",
      "2 0.5898832345765075 1.7750084836982565\n",
      "3 0.6186754966887418 1.6279348977279635\n",
      "4 0.5927152317880795 1.6607935371910922\n",
      "[LOG] avg. concordance: 0.591859881491809\n",
      "[LOG] avg. ipec: 1.7437986629659339\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 64, lmbda = 0.12\n",
      "0 0.5666608574416173 1.8971115109191923\n",
      "1 0.6064830951551063 1.514568992079815\n",
      "2 0.6082694318577901 1.6649607527752655\n",
      "3 0.598719646799117 1.6534931004523152\n",
      "4 0.5949668874172186 1.6823499680198848\n",
      "[LOG] avg. concordance: 0.59501998373417\n",
      "[LOG] avg. ipec: 1.6824968648492944\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 64, lmbda = 0.15\n",
      "0 0.5757232485186476 1.816291360095274\n",
      "1 0.6178110840013942 1.5002946724371133\n",
      "2 0.6194231439525967 1.5428217994529014\n",
      "3 0.6168211920529801 1.5667103561864173\n",
      "4 0.6029139072847682 1.5816133016538612\n",
      "[LOG] avg. concordance: 0.6065385151620774\n",
      "[LOG] avg. ipec: 1.6015462979651136\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 128, lmbda = 0.0\n",
      "0 0.5373387940048797 2.3388674336311723\n",
      "1 0.5852213314743813 1.8702866489469379\n",
      "2 0.5741983269431857 1.9610337505877224\n",
      "3 0.5795584988962472 1.9159859127861951\n",
      "4 0.5873289183222958 1.6931652330756737\n",
      "[LOG] avg. concordance: 0.5727291739281979\n",
      "[LOG] avg. ipec: 1.9558677958055402\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 128, lmbda = 0.01\n",
      "0 0.5284942488672011 2.4317379772548953\n",
      "1 0.5823893342628094 1.8456581654687865\n",
      "2 0.5686650400836528 2.0474152478183916\n",
      "3 0.5958498896247241 1.903517737763882\n",
      "4 0.5768211920529801 1.9464164590035824\n",
      "[LOG] avg. concordance: 0.5704439409782734\n",
      "[LOG] avg. ipec: 2.0349491174619074\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 128, lmbda = 0.02\n",
      "0 0.5219153014987801 2.5188646448585845\n",
      "1 0.5781631230393866 1.9643377889600673\n",
      "2 0.5630446148483792 2.158946151371321\n",
      "3 0.59841059602649 1.9141894183163242\n",
      "4 0.5627814569536423 1.9610400954581777\n",
      "[LOG] avg. concordance: 0.5648630184733356\n",
      "[LOG] avg. ipec: 2.1034756197928948\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 128, lmbda = 0.06\n",
      "0 0.5269693272917393 2.4835389465921787\n",
      "1 0.5843935169048449 1.7303910306486576\n",
      "2 0.5635674451028233 2.205770315748789\n",
      "3 0.5888300220750552 1.7555503351643962\n",
      "4 0.587991169977925 1.7288581776623702\n",
      "[LOG] avg. concordance: 0.5703502962704775\n",
      "[LOG] avg. ipec: 1.9808217611632783\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 128, lmbda = 0.1\n",
      "0 0.5545921924015337 2.060300665226604\n",
      "1 0.6167654234925061 1.4820755412161026\n",
      "2 0.5945451376786337 1.749236809084437\n",
      "3 0.6153642384105961 1.6554014431431174\n",
      "4 0.590066225165563 1.68777280629837\n",
      "[LOG] avg. concordance: 0.5942666434297664\n",
      "[LOG] avg. ipec: 1.7269574529937262\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 128, lmbda = 0.12\n",
      "0 0.5698414081561519 1.9533101783389777\n",
      "1 0.6031282676890902 1.577007866256693\n",
      "2 0.6144562565353782 1.6178078510245795\n",
      "3 0.5985430463576159 1.6996717877016223\n",
      "4 0.5943046357615894 1.6674484820193196\n",
      "[LOG] avg. concordance: 0.5960547228999651\n",
      "[LOG] avg. ipec: 1.7030492330682385\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 128, lmbda = 0.15\n",
      "0 0.580036598117811 1.823043528723169\n",
      "1 0.6232136632973161 1.4837984878499395\n",
      "2 0.6085744161728825 1.586683120836341\n",
      "3 0.5998675496688741 1.6066677821961288\n",
      "4 0.5877262693156733 1.6847724548586638\n",
      "[LOG] avg. concordance: 0.5998836993145115\n",
      "[LOG] avg. ipec: 1.6369930748928485\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 256, lmbda = 0.0\n",
      "0 0.5292784942488672 2.475451243891513\n",
      "1 0.5804722899965145 1.873413411160459\n",
      "2 0.5976385500174277 1.6726861127320183\n",
      "3 0.6006622516556291 1.811167652241392\n",
      "4 0.5752759381898455 1.9276809834929416\n",
      "[LOG] avg. concordance: 0.5766655048216568\n",
      "[LOG] avg. ipec: 1.9520798807036646\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 256, lmbda = 0.01\n",
      "0 0.524093760892297 2.5114795853442518\n",
      "1 0.5399529452771 1.8258135533586515\n",
      "2 0.5711484837922621 2.0463992959621065\n",
      "3 0.6016777041942605 1.7754735647014523\n",
      "4 0.5632229580573952 1.9997540352347631\n",
      "[LOG] avg. concordance: 0.560019170442663\n",
      "[LOG] avg. ipec: 2.031784006920245\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 256, lmbda = 0.02\n",
      "0 0.5170791216451726 2.615634092288134\n",
      "1 0.573326943185779 2.0185938717274654\n",
      "2 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 nan\n",
      "3 0.5805298013245033 2.001797954101557\n",
      "4 0.5726269315673289 1.9261505690675769\n",
      "[LOG] avg. concordance: 0.5487125595445568\n",
      "[LOG] avg. ipec: nan\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 256, lmbda = 0.06\n",
      "0 0.5417828511676542 2.2100797542131825\n",
      "1 0.6008191007319623 1.6610329823738685\n",
      "2 0.5 nan\n",
      "3 0.5865783664459161 1.7234505565994627\n",
      "4 0.5632671081677704 2.0011451353358347\n",
      "[LOG] avg. concordance: 0.5584894853026606\n",
      "[LOG] avg. ipec: nan\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 256, lmbda = 0.1\n",
      "0 0.5569013593586616 2.033712465473297\n",
      "1 0.6231265249215755 1.4725248262795303\n",
      "2 0.6031282676890902 1.6698057756434945\n",
      "3 0.5993377483443708 1.6196078048957272\n",
      "4 0.5954083885209713 1.6463350902046565\n",
      "[LOG] avg. concordance: 0.5955804577669339\n",
      "[LOG] avg. ipec: 1.688397192499341\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 256, lmbda = 0.12\n",
      "0 0.5670529801324503 1.961077106598572\n",
      "1 0.6109271523178808 1.530451236844818\n",
      "2 0.6144998257232486 1.5632084081537083\n",
      "3 0.612626931567329 1.5678203578732874\n",
      "4 0.5994260485651214 1.6332957850028804\n",
      "[LOG] avg. concordance: 0.600906587661206\n",
      "[LOG] avg. ipec: 1.6511705788946531\n",
      "-------------------------------------------------------\n",
      "[LOG] first_layer = 256, lmbda = 0.15\n",
      "0 0.5716277448588358 1.8804788321163282\n",
      "1 0.6160683164865807 1.504745292951874\n",
      "2 0.603999651446497 1.70209228258738\n",
      "3 0.5970860927152318 1.6665946168551973\n",
      "4 0.5955408388520971 1.615145436118834\n",
      "[LOG] avg. concordance: 0.5968645288718486\n",
      "[LOG] avg. ipec: 1.6738112921259227\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "first_layers = [8, 16, 32, 64, 128, 256]\n",
    "lmbdas = [0., 0.01, 0.02, 0.06, 0.1, 0.12, 0.15]\n",
    "dataset_name = dataset_names[idx]\n",
    "dataset_idx = dataset_idxs[idx]\n",
    "filename = filename_generator(\"NNC\", False, [dataset_idx])\n",
    "# concordances, ipecs = load_score_containers([dataset_name], [first_layers, lmbdas])\n",
    "concordances = {}\n",
    "ipecs = {}\n",
    "\n",
    "print(\"\\nFor the \" + dataset_name + \" dataset:\")\n",
    "\n",
    "for row, first_layer in enumerate(first_layers):\n",
    "    for col, lmbda in enumerate(lmbdas):\n",
    "        print(\"[LOG] first_layer = {}, lmbda = {}\".format(\n",
    "            first_layer, lmbda))\n",
    "\n",
    "        tmp_concordances = []\n",
    "        tmp_ipecs = []\n",
    "\n",
    "        for index, cur_train in enumerate(train_dfs[dataset_name]):\n",
    "            print(index, end=\" \")\n",
    "            cur_test = test_dfs[dataset_name][index]\n",
    "            model = NeuralNetworkCox(first_layer_size=first_layer, lmbda=lmbda, verbose=0)\n",
    "            model.fit(cur_train, duration_col='LOS', event_col='OUT')\n",
    "            concordance, ipec_score = calc_scores(model, cur_test, unique_times[dataset_name])\n",
    "            print(concordance, ipec_score[int(len(ipec_score) * 0.8)])\n",
    "\n",
    "            tmp_concordances.append(concordance)\n",
    "            tmp_ipecs.append(ipec_score)\n",
    "\n",
    "        avg_concordance = np.average(tmp_concordances)\n",
    "        avg_ipec = np.average(tmp_ipecs, axis=0)\n",
    "        print(\"[LOG] avg. concordance:\", avg_concordance)\n",
    "        print(\"[LOG] avg. ipec:\", avg_ipec[int(len(avg_ipec) * 0.8)])\n",
    "\n",
    "        concordances[(first_layer, lmbda)] = avg_concordance\n",
    "        ipecs[(first_layer, lmbda)] = avg_ipec\n",
    "\n",
    "        print(\"-------------------------------------------------------\")\n",
    "\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump([first_layers, lmbdas, concordances, ipecs], f, pickle.HIGHEST_PROTOCOL)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "first_layers = [8, 16, 32, 64, 96, 128, 192, 256]\n",
    "lmbdas = [0., 0.01, 0.02]\n",
    "dataset_name = dataset_names[idx]\n",
    "unique_time = unique_times[dataset_name]\n",
    "dataset_idx = dataset_idxs[idx]\n",
    "filename = filename_generator(\"NNC\", False, [dataset_idx])\n",
    "# concordances, ipecs = load_score_containers([dataset_name], [first_layers, lmbdas])\n",
    "concordances = {}\n",
    "ipecs = {}\n",
    "\n",
    "print(\"\\nFor the \" + dataset_name + \" dataset:\")\n",
    "\n",
    "for row, first_layer in enumerate(first_layers):\n",
    "    for col, lmbda in enumerate(lmbdas):\n",
    "        print(\"[LOG] first_layer = {}, lmbda = {}\".format(first_layer, lmbda))\n",
    "\n",
    "        tmp_concordances = []\n",
    "        tmp_ipecs = []\n",
    "\n",
    "        for index, cur_train in enumerate(train_dfs[dataset_name]):\n",
    "            print(index, end=\" \")\n",
    "            cur_test = test_dfs[dataset_name][index]\n",
    "            model = NeuralNetworkCox(first_layer_size=first_layer, lmbda=lmbda, epochs=2000, verbose=0)\n",
    "            model.fit(cur_train, duration_col='LOS', event_col='OUT')\n",
    "            concordance, ipec_score_list = calc_scores(model, cur_test, unique_time)\n",
    "            print(concordance)\n",
    "\n",
    "            tmp_concordances.append(concordance)\n",
    "            tmp_ipecs.append(ipec_score)\n",
    "\n",
    "        avg_concordance = np.average(tmp_concordances)\n",
    "        avg_ipec = np.average(tmp_ipecs)\n",
    "        print(\"[LOG] avg. concordance:\", avg_concordance)\n",
    "        print(\"[LOG] avg. ipec:\", avg_ipec)\n",
    "\n",
    "        concordances[dataset_name][row] = avg_concordance\n",
    "        ipecs[dataset_name][row] = avg_ipec\n",
    "\n",
    "        print(\"-------------------------------------------------------\")\n",
    "\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump([first_layers, lmbdas, concordances, ipecs], f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For the pancreatitis dataset:\n",
      "[LOG] first_layer_size = 8\n",
      "[LOG] avg. concordance: 0.5753215488215488\n",
      "[LOG] avg. ipec: 3.4120316130733066\n",
      "[LOG] first_layer_size = 16\n",
      "[LOG] avg. concordance: 0.5736048581048582\n",
      "[LOG] avg. ipec: 3.432582309174939\n",
      "[LOG] first_layer_size = 32\n",
      "[LOG] avg. concordance: 0.5785473785473786\n",
      "[LOG] avg. ipec: 3.38209070774906\n",
      "[LOG] first_layer_size = 64\n",
      "[LOG] avg. concordance: 0.5774300144300145\n",
      "[LOG] avg. ipec: 3.392501325919244\n",
      "[LOG] first_layer_size = 128\n",
      "[LOG] avg. concordance: 0.5768600288600289\n",
      "[LOG] avg. ipec: 3.3949948105549934\n",
      "\n",
      "For the ich dataset:\n",
      "[LOG] first_layer_size = 8\n",
      "[LOG] avg. concordance: 0.5630347391657953\n",
      "[LOG] avg. ipec: 2.1524096315226284\n",
      "[LOG] first_layer_size = 16\n",
      "[LOG] avg. concordance: 0.567214941326827\n",
      "[LOG] avg. ipec: 2.0818974789897733\n",
      "[LOG] first_layer_size = 32\n",
      "[LOG] avg. concordance: 0.5542585105146973\n",
      "[LOG] avg. ipec: 2.1669880399180133\n",
      "[LOG] first_layer_size = 64\n",
      "[LOG] avg. concordance: 0.5681728825374694\n",
      "[LOG] avg. ipec: 2.0638685933225243\n",
      "[LOG] first_layer_size = 128\n",
      "[LOG] avg. concordance: 0.5685181828744046\n",
      "[LOG] avg. ipec: 2.033646468296669\n"
     ]
    }
   ],
   "source": [
    "first_layer_sizes = [8, 16, 32, 64, 128]\n",
    "concordance_result = {}\n",
    "ipec_result = {}\n",
    "\n",
    "dataset_name = dataset_names[0]\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    unique_time = unique_times[dataset_name]\n",
    "    concordances = []\n",
    "    ipecs = []\n",
    "    print(\"\\nFor the \" + dataset_name + \" dataset:\")\n",
    "    \n",
    "    for row, first_layer_size in enumerate(first_layer_sizes):\n",
    "        print(\"[LOG] first_layer_size = {}\".format(first_layer_size))\n",
    "        \n",
    "        tmp_concordances = []\n",
    "        tmp_ipecs = []\n",
    "\n",
    "        for index, cur_train in enumerate(train_dfs[dataset_name]):\n",
    "            cur_test = test_dfs[dataset_name][index]\n",
    "            \n",
    "            model = NeuralNetworkCox(first_layer_size=first_layer_size, epochs=2000, verbose=0)\n",
    "            model.fit(cur_train, duration_col='LOS', event_col='OUT')\n",
    "            concordance, ipec_score_list = calc_scores(model, cur_test, unique_time)\n",
    "            \n",
    "            tmp_concordances.append(concordance)\n",
    "            tmp_ipecs.append(ipec_score_list)\n",
    "\n",
    "        avg_concordance = np.average(tmp_concordances)\n",
    "        avg_ipec = np.average(tmp_ipecs, axis=0)\n",
    "        print(\"[LOG] avg. concordance:\", avg_concordance)\n",
    "        print(\"[LOG] avg. ipec:\", avg_ipec[int(len(avg_ipec) * 0.8)])\n",
    "\n",
    "        concordances.append(avg_concordance)\n",
    "        ipecs.append(avg_ipec)\n",
    "    \n",
    "    concordance_result[dataset_name] = concordances\n",
    "    ipec_result[dataset_name] = ipecs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For the ich dataset:\n",
      "[LOG] first_layer_size = 128\n",
      "[LOG] avg. concordance: 0.5812185430463577\n",
      "[LOG] avg. ipec: 1.8740793022331967\n",
      "[LOG] first_layer_size = 256\n",
      "[LOG] avg. concordance: 0.5755504821656791\n",
      "[LOG] avg. ipec: 1.9143238912932723\n"
     ]
    }
   ],
   "source": [
    "dataset_name = dataset_names[1]\n",
    "\n",
    "unique_time = unique_times[dataset_name]\n",
    "concordances = []\n",
    "ipecs = []\n",
    "print(\"\\nFor the \" + dataset_name + \" dataset:\")\n",
    "\n",
    "for row, first_layer_size in enumerate([128, 256]):\n",
    "    print(\"[LOG] first_layer_size = {}\".format(first_layer_size))\n",
    "\n",
    "    tmp_concordances = []\n",
    "    tmp_ipecs = []\n",
    "\n",
    "    for index, cur_train in enumerate(train_dfs[dataset_name]):\n",
    "        cur_test = test_dfs[dataset_name][index]\n",
    "\n",
    "        model = NeuralNetworkCox(first_layer_size=first_layer_size, epochs=2000, verbose=0, lmbda=0.1)\n",
    "        model.fit(cur_train, duration_col='LOS', event_col='OUT')\n",
    "        concordance, ipec_score_list = calc_scores(model, cur_test, unique_time)\n",
    "\n",
    "        tmp_concordances.append(concordance)\n",
    "        tmp_ipecs.append(ipec_score_list)\n",
    "\n",
    "    avg_concordance = np.average(tmp_concordances)\n",
    "    avg_ipec = np.average(tmp_ipecs, axis=0)\n",
    "    print(\"[LOG] avg. concordance:\", avg_concordance)\n",
    "    print(\"[LOG] avg. ipec:\", avg_ipec[int(len(avg_ipec) * 0.8)])\n",
    "\n",
    "    concordances.append(avg_concordance)\n",
    "    ipecs.append(avg_ipec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
